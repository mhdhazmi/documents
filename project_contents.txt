
// File Path: .cursor/mcp.json

{
  "mcpServers": {
    "context7": {
      "command": "npx",
      "args": ["-y", "@upstash/context7-mcp@latest"]
    },
    "convex": {
      "command": "npx",
      "args": ["-y", "convex@latest", "mcp", "start"]
    }
  }
} 


// File Path: .vscode/settings.json

{
    "postman.settings.dotenv-detection-notification-visibility": false
}


// File Path: components.json

{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "",
    "css": "src/app/globals.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  },
  "iconLibrary": "lucide"
}


// File Path: convex/api.ts

import { httpAction } from "./_generated/server";
import { Id } from "./_generated/dataModel";
import { api, internal } from "./_generated/api";
import { cleanTextWithOpenAI } from "./utils/cleaner";
import { readableStreamFromIterable } from "./utils/stream";

// Centralized CORS headers function to ensure consistency
const getCorsHeaders = (request: Request): Record<string, string> => {
  // Get the origin from the request or fall back to configured origin
  const requestOrigin = request.headers.get("Origin");
  
  // Determine which origin to allow
  // If the origin is from our allowed domains, return that specific origin
  // This is more secure than using a wildcard
  const allowedOrigins = [
    "http://localhost:3000",
    
    "http://localhost:3001",           // Local development
    "https://your-production-domain.com", // Production
    process.env.CLIENT_ORIGIN || ""    // Environment variable if set
  ].filter(Boolean);
  
  // Determine which origin to use in the response
  let originToAllow = "*"; // Default fallback (less secure)
  
  if (requestOrigin) {
    if (allowedOrigins.includes(requestOrigin)) {
      // If it's in our allowed list, echo it back
      originToAllow = requestOrigin;
    } else if (requestOrigin.endsWith(".vercel.app")) {
      // Preview deployments (optional)
      originToAllow = requestOrigin;
    }
  }
  
  return {
    "Access-Control-Allow-Origin": originToAllow,
    "Access-Control-Allow-Methods": "POST, OPTIONS, GET",
    "Access-Control-Allow-Headers": "Content-Type, Authorization, X-Requested-With",
    "Access-Control-Max-Age": "86400", // 24 hours
    "Vary": "Origin" // Important when using dynamic origins
  };
};

export const cleanHandler = httpAction(async (ctx, req) => {
  // Get CORS headers for this request
  const corsHeaders = getCorsHeaders(req);
  
  // Handle preflight OPTIONS request
  if (req.method === "OPTIONS") {
    return new Response(null, { 
      status: 204, 
      headers: corsHeaders 
    });
  }

  // Handle actual request
  try {
    if (req.method !== "POST") {
      return new Response("Method not allowed", { 
        status: 405, 
        headers: corsHeaders 
      });
    }
    
    // Parse request body
    const body = await req.json().catch(err => {
      console.error("Failed to parse request body", err);
      throw new Error("Invalid JSON in request body");
    });
    
    const { pdfId, source } = body as { pdfId: Id<"pdfs">; source: "gemini" | "replicate" };
    
    if (!pdfId || !source) {
      return new Response("Missing required fields: pdfId and source", {
        status: 400,
        headers: corsHeaders
      });
    }
    
    console.log("Processing request for pdfId:", pdfId, "source:", source);
    
    // Check if PDF exists
    const pdf = await ctx.runQuery(api.pdf.queries.getPdf, { pdfId });
    if (!pdf) {
      return new Response("PDF not found in database", { 
        status: 404, 
        headers: corsHeaders 
      });
    }
    
    // Get OCR status
    const [geminiId] = await ctx.runQuery(api.ocr.gemini.queries.getOcrByPdfId, { pdfId });
    const [replicateId] = await ctx.runQuery(api.ocr.replicate.queries.getOcrByPdfId, { pdfId });
    const embeddingRecord = await ctx.runQuery(internal.ingest.ingest.getEmbedding, { pdfId });
    
    // Update status to "started"
    await ctx.runMutation(internal.ocr.openai.mutations.updateCleanedStatus, { 
      pdfId, 
      source, 
      cleaningStatus: "started", 
      cleanedText: "" 
    });
    
    // Get text to clean based on source
    let text;
    if (source === "gemini") {
      if (geminiId?.ocrStatus !== "completed") {
        return new Response("Gemini OCR not completed", { 
          status: 400, 
          headers: corsHeaders 
        });
      }
      const geminiResults = await ctx.runQuery(api.ocr.gemini.queries.getOcrByPdfId, { pdfId });
      text = geminiResults?.[0]?.extractedText || "";
    } else if (source === "replicate") {
      if (replicateId?.ocrStatus !== "completed") {
        return new Response("Replicate OCR not completed", { 
          status: 400, 
          headers: corsHeaders 
        });
      }
      const replicateResults = await ctx.runQuery(api.ocr.replicate.queries.getOcrByPdfId, { pdfId });
      text = replicateResults?.[0]?.extractedText || "";
    } else {
      return new Response(`Invalid source: ${source}`, { 
        status: 400, 
        headers: corsHeaders 
      });
    }
    
    if (!text || text.trim() === "") {
      return new Response("No text found to clean", { 
        status: 400, 
        headers: corsHeaders 
      });
    }
    
    // Set up streaming response
    const { readable, writable } = new TransformStream();
    const writer = writable.getWriter();
    const encoder = new TextEncoder();
    
    // Process in background
    void (async () => {
      try {
        let fullText = "";
        
        // Use the new cleanTextWithOpenAI utility
        const generator = cleanTextWithOpenAI(text);
        for await (const chunk of generator) {
          await writer.write(encoder.encode(chunk));
          fullText += chunk;
        }
        
        // Get the final result from the generator
        const result = await generator.next();
        if (result.done && result.value) {
          fullText = result.value;
        }
        
        // Save completed result
        await ctx.runMutation(internal.ocr.openai.mutations.saveCleanedResults, {
          pdfId,
          source,
          cleanedText: fullText,
          cleaningStatus: "completed"
        });
        
        // Create embedding if needed
        if (source === "gemini" && !embeddingRecord) {
          await ctx.runAction(api.ingest.ingest.chunkAndEmbed, { pdfId });
        }
      } catch (error) {
        console.error("Error in streaming process:", error);
        // Can't update response headers at this point
      } finally {
        await writer.close();
      }
    })();
    
    // Return streaming response with CORS headers
    return new Response(readable, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        ...corsHeaders
      }
    });
    
  } catch (error) {
    console.error("Error in clean handler:", error);
    return new Response(
      JSON.stringify({ 
        error: true, 
        message: error instanceof Error ? error.message : String(error) 
      }), 
      { 
        status: 500, 
        headers: {
          "Content-Type": "application/json",
          ...corsHeaders
        } 
      }
    );
  }
});

// convex/http.ts (update the cleanPageHandler)
export const cleanPageHandler = httpAction(async (ctx, req) => {
  // Get CORS headers for this request
  const corsHeaders = getCorsHeaders(req);
  
  // Handle preflight OPTIONS request
  if (req.method === "OPTIONS") {
    return new Response(null, { 
      status: 204, 
      headers: corsHeaders 
    });
  }

  // Handle actual request
  try {
    if (req.method !== "POST") {
      return new Response("Method not allowed", { 
        status: 405, 
        headers: corsHeaders 
      });
    }
    
    // Parse request body
    const body = await req.json().catch(err => {
      console.error("Failed to parse request body", err);
      throw new Error("Invalid JSON in request body");
    });
    
    const { pageId, source } = body as { pageId: Id<"pages">; source: "gemini" | "replicate" };
    
    if (!pageId || !source) {
      return new Response("Missing required fields: pageId and source", {
        status: 400,
        headers: corsHeaders
      });
    }
    
    // Check idempotency first
    const status = await ctx.runMutation(internal.ocr.openai.mutations.startPageCleaning, { 
      pageId, 
      source 
    });
    
    if (status === "completed") {
      const cleaned = await ctx.runQuery(
        api.ocr.openai.queries.getPageCleanedResults,
        { pageId, source }
      );

      const text = cleaned?.cleanedText ?? "";

      if (text.trim() === "") {
        // Nothing to stream – tell the client gracefully.
        return new Response(null, { status: 204, headers: corsHeaders });
      }

      return new Response(text, {
        status: 200,
        headers: {
          "Content-Type": "text/plain; charset=utf-8",
          ...corsHeaders,
        },
      });
    }
    
    console.log("Processing request for pageId:", pageId, "source:", source);
    
    // Check if page exists
    const page = await ctx.runQuery(api.pdf.queries.getPdfPage, { pageId });
    if (!page) {
      return new Response("Page not found in database", { 
        status: 404, 
        headers: corsHeaders 
      });
    }
    
    // Get OCR results based on source
    let ocrResults;
    if (source === "gemini") {
      ocrResults = await ctx.runQuery(api.ocr.gemini.queries.getPageOcrResults, { pageId });
    } else if (source === "replicate") {
      ocrResults = await ctx.runQuery(api.ocr.replicate.queries.getPageOcrResults, { pageId });
    } else {
      return new Response(`Invalid source: ${source}`, { 
        status: 400, 
        headers: corsHeaders 
      });
    }
    
    if (!ocrResults?.ocrResults || ocrResults.ocrResults.ocrStatus !== "completed") {
      return new Response(`${source} OCR not completed for this page`, { 
        status: 400, 
        headers: corsHeaders 
      });
    }
    
    const text = ocrResults.ocrResults.extractedText || "";
    if (!text || text.trim() === "") {
      return new Response("No text found to clean", { 
        status: 400, 
        headers: corsHeaders 
      });
    }
    
    // Set up streaming response
    const { readable, writable } = new TransformStream();
    const writer = writable.getWriter();
    const encoder = new TextEncoder();
    
    // Process in background
    void (async () => {
      try {
        let fullText = "";
        
        // Use the new cleanTextWithOpenAI utility
        const generator = cleanTextWithOpenAI(text);
        for await (const chunk of generator) {
          await writer.write(encoder.encode(chunk));
          fullText += chunk;
        }
        
        // Get the final result from the generator
        const result = await generator.next();
        if (result.done && result.value) {
          fullText = result.value;
        }
        
        // Save completed result
        await ctx.runMutation(internal.ocr.openai.mutations.savePageCleanedResults, {
          pageId,
          source,
          cleanedText: fullText,
          cleaningStatus: "completed"
        });
      } catch (error) {
        console.error("Error in streaming process:", error);
        // Can't update response headers at this point
      } finally {
        await writer.close();
      }
    })();
    
    // Return streaming response with CORS headers
    return new Response(readable, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        ...corsHeaders
      }
    });
    
  } catch (error) {
    console.error("Error in cleanPage handler:", error);
    return new Response(
      JSON.stringify({ 
        error: true, 
        message: error instanceof Error ? error.message : String(error) 
      }), 
      { 
        status: 500, 
        headers: {
          "Content-Type": "application/json",
          ...corsHeaders
        } 
      }
    );
  }
});


// File Path: convex/concatenate/actions.ts

// convex/concatenate/actions.ts
import { internalAction } from "../_generated/server";
import { internal } from "../_generated/api";
import { v } from "convex/values";


export const recheckConcatenation = internalAction({
  args: {
    pdfId: v.id("pdfs"),
    preferredSource: v.optional(v.union(v.literal("gemini"), v.literal("replicate"))),
    retryCount: v.number(),
  },
  handler: async (ctx, args) => {
    try {
      // Restart the concatenation workflow with updated retry count
      await ctx.runMutation(internal.workflow.concatenateWorkflow.startConcatenateWorkflow, args);
      
      return {
        success: true,
        message: `Restarted concatenation workflow for PDF ${args.pdfId} (retry ${args.retryCount})`,
      };
    } catch (error) {
      console.error(`Error restarting concatenation workflow for PDF ${args.pdfId}:`, error);
      throw error;
    }
  },
});


// File Path: convex/concatenate/mutations.ts

// convex/concatenate/mutations.ts
import { internalMutation } from "../_generated/server";
import { v } from "convex/values";

export const saveConcatenatedText = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
    text: v.string(),
  },
  handler: async (ctx, args) => {
    // Check if we already have concatenated results for this PDF and source
    const existing = await ctx.db
      .query("openaiOcrResults")
      .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
      .filter((q) => q.eq(q.field("source"), args.source))
      .first();
    
    if (existing) {
      // Update existing record
      await ctx.db.patch(existing._id, {
        cleanedText: args.text,
        cleaningStatus: "completed",
        processedAt: Date.now(),
      });
    } else {
      // Create new record
      await ctx.db.insert("openaiOcrResults", {
        pdfId: args.pdfId,
        cleanedText: args.text,
        cleaningStatus: "completed",
        processedAt: Date.now(),
        source: args.source,
      });
    }
    
    // Update the PDF status to indicate processing is complete
    await ctx.db.patch(args.pdfId, {
      status: "processed",
    });
  },
});


// File Path: convex/concatenate/queries.ts

// convex/concatenate/queries.ts
import { internalQuery } from "../_generated/server";
import { v } from "convex/values";
import { Id } from "../_generated/dataModel";

export const areAllPagesComplete = internalQuery({
  args: {
    pdfId: v.id("pdfs"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  },
  handler: async (ctx, args) => {
    // 1. Get all pages for this PDF
    const pages = await ctx.db
      .query("pages")
      .withIndex("byPdfId", (q) => q.eq("pdfId", args.pdfId))
      .collect();
    
    if (pages.length === 0) {
      return false;
    }
    
    // 2. Check if every page has cleaned results for the specified source
    for (const page of pages) {
      const cleaned = await ctx.db
        .query("openaiCleanedPage")
        .withIndex("by_page_id", (q) => q.eq("pageId", page._id))
        .filter((q) => 
          q.eq(q.field("source"), args.source) && 
          q.eq(q.field("cleaningStatus"), "completed")
        )
        .first();
      
      // If any page doesn't have complete cleaned results, return false
      if (!cleaned) {
        return false;
      }
    }
    
    // All pages have completed cleaned results
    return true;
  },
});

export const getConcatenatedText = internalQuery({
  args: {
    pdfId: v.id("pdfs"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  },
  handler: async (ctx, args) => {
    // 1. Get all pages for this PDF in order
    const pages = await ctx.db
      .query("pages")
      .withIndex("byPdfIdAndPageNumber", (q) => q.eq("pdfId", args.pdfId))
      .collect();
    
    if (pages.length === 0) {
      return "";
    }
    
    // 2. Get the cleaned text for each page in order
    const pageTexts: string[] = [];
    
    for (const page of pages) {
      const cleaned = await ctx.db
        .query("openaiCleanedPage")
        .withIndex("by_page_id", (q) => q.eq("pageId", page._id))
        .filter((q) => 
          q.eq(q.field("source"), args.source) && 
          q.eq(q.field("cleaningStatus"), "completed")
        )
        .first();
      
      if (cleaned?.cleanedText) {
        pageTexts.push(
          `--- PAGE ${page.pageNumber} ---\n${cleaned.cleanedText}`
        );
      } else {
        pageTexts.push(
          `--- PAGE ${page.pageNumber} ---\n[No text available]`
        );
      }
    }
    
    // 3. Join all page texts with double newlines
    return pageTexts.join('\n\n');
  },
});


// File Path: convex/config.ts

// convex/config.ts
// Configuration file for OCR and other services

// Replicate OCR Configuration
export const replicate = {
    model: "lucataco/olmocr-7b",
    modelVersion: "d96720d5a835ed7b48f2951a5e5f4e247ed724f6fd96c6b96b5c7234f635065f",
    batchSize: 7,
    maxRetries: 3,
    retryDelayMs: 10000, // default retry delay in ms if not specified by API
    timeoutMs: 5000, // timeout between polling requests
    temperature: 0.1, // Add this parameter to reduce randomness
};

// Gemini OCR Configuration
export const gemini = {
    model: "gemini-2.5-pro-exp-03-25",
    fileProcessingPollingIntervalMs: 1000,
    prompt: `🎯 Objective
Perform high-accuracy OCR (Optical Character Recognition) on Arabic-language documents. The input may be a scanned document, photographed text, or a PDF containing Arabic script.

📌 Instructions
Please follow these guidelines strictly:

Language: Arabic only. Do not detect or output any other language.

Direction: Read text from right to left.

Tags: 🚫 Do not include any XML, HTML, or formatting tags in the output. Only raw text is required.

Diacritics: Preserve Arabic diacritics (like َ ُ ِ ّ ) if they exist in the original image.

Punctuation & Symbols: Preserve punctuation marks (، ؛ ؟ .) and numerals as they appear.

Character Forms: Recognize context-based Arabic letter shapes (isolated, initial, medial, final).

Ligatures: Correctly handle common ligatures such as "لا" and words where characters are joined naturally.

Line and Paragraph Structure:

Maintain logical order and spacing of lines.

Avoid inserting artificial line breaks unless they exist in the original.

Mixed Content:

If non-Arabic text (e.g. English words, numbers) is present, retain it only if part of the original content.

Preserve inline structure (e.g. English terms within Arabic sentences).`
};

// OpenAI Configuration
export const openai = {
    model: "gpt-4o-mini",
    streamingModel: "gpt-4o-mini", // Used in API streaming endpoints
    temperature: 0.1,
    systemPrompt: `
    🧹 Final Cleanup Model Prompt (Arabic Text Post-OCR Correction)
🎯 Objective
Refine and correct Arabic text that was previously extracted via OCR. The goal is to clean up common OCR mistakes such as incorrect characters or distorted words that do not fit the context.

📌 Instructions
Carefully revise the input text by applying the following rules:

Language: Arabic only. Ignore any embedded formatting or tagging from OCR output.

Contextual Corrections:

Fix words that contain incorrect characters and result in a loss of meaning.

Use the surrounding context of each word to infer the correct spelling or structure.

Spelling and Grammar:

Apply standard Arabic grammar and spelling rules.

Correct misspellings caused by character swaps or OCR noise.

Do Not Add Content:

Do not insert new words that were not present or implied in the original.

Only correct what appears to be a likely OCR mistake.

Diacritics:

Preserve diacritics if present, but it's okay to omit them if missing.

Structure Preservation:

Maintain paragraph and sentence structure as-is from the OCR output.

Avoid breaking up lines or rearranging the order of words unless absolutely necessary for clarity.

make sure the returned text is RTL
`,
    userPromptPrefix: "Clean and reformat the following OCR text:\n\n"
};

// General OCR Configuration
export const ocr = {
    performOcrPrompt: "Perform OCR on the following document, clean the text and translate it to both English and Arabic\ntext = {'Arabic': string, 'English': string}\nReturn: Array<text>",
    statusTypes: {
        processing: "processing",
        success: "success",
        failed: "failed"
    }
}; 

// Embedding configuration
export const embedding = {
    model: 'text-embedding-3-small',
    dimensions: 1536,
    chunking: {
        chunkSize: 8000,
        chunkOverlap: 500
    }
};


// File Path: convex/CONFIG_README.md

# OCR Configuration System

This document explains the configuration system for the OCR functionality in the Convex application.

## Overview

All configuration values for the OCR system have been centralized in the `convex/config.ts` file. This allows for easy customization of various aspects of the OCR functionality without having to modify the code directly.

## Configuration Structure

The configuration is organized into several sections:

### Replicate OCR Configuration

```typescript
export const replicate = {
  model: "lucataco/olmocr-7b",
  modelVersion: "d96720d5a835ed7b48f2951a5e5f4e247ed724f6fd96c6b96b5c7234f635065f",
  batchSize: 5,
  maxRetries: 3,
  retryDelayMs: 10000, // default retry delay in ms if not specified by API
  timeoutMs: 5000, // timeout between polling requests
};
```

- `model`: The Replicate model to use for OCR
- `modelVersion`: The specific model version to use
- `batchSize`: Number of pages to process in parallel
- `maxRetries`: Maximum number of retry attempts for failed API calls
- `retryDelayMs`: Default delay between retries in milliseconds
- `timeoutMs`: Timeout for polling requests

### Gemini OCR Configuration

```typescript
export const gemini = {
  model: "gemini-1.5-flash",
  fileProcessingPollingIntervalMs: 5000,
  prompt: "Perform OCR on the PDF document and extract the text content. Return the text content in a structured format, including headers, paragraphs, and tables. Do not change the original language of the document."
};
```

- `model`: The Gemini model to use for OCR
- `fileProcessingPollingIntervalMs`: Polling interval when waiting for file processing
- `prompt`: The prompt to send to Gemini for OCR extraction

### OpenAI Configuration

```typescript
export const openai = {
  model: "gpt-4o",
  temperature: 0.3,
  systemPrompt: "You are an expert at cleaning and formatting OCR text. Your job is to take raw OCR output and clean it up - fix formatting issues, correct obvious OCR errors, properly structure paragraphs, tables, and sections. Preserve all original content but make it more readable.",
  userPromptPrefix: "Clean and reformat the following OCR text:\n\n"
};
```

- `model`: The OpenAI model to use for text cleanup
- `temperature`: The temperature parameter for the API call
- `systemPrompt`: The system prompt to send to OpenAI
- `userPromptPrefix`: The prefix to add to the user prompt

### General OCR Configuration

```typescript
export const ocr = {
  performOcrPrompt: "Perform OCR on the following document, clean the text and translate it to both English and Arabic\ntext = {'Arabic': string, 'English': string}\nReturn: Array<text>",
  statusTypes: {
    processing: "processing",
    success: "success",
    failed: "failed"
  }
};
```

- `performOcrPrompt`: The prompt used in the main OCR functionality
- `statusTypes`: Standard status types used across the application

## How to Customize

To modify any of these settings, simply edit the `convex/config.ts` file and update the values as needed. The changes will be applied the next time the corresponding code runs.

For example, to update the OpenAI model:

```typescript
// In convex/config.ts
export const openai = {
  model: "gpt-4-turbo", // Changed from gpt-4o to gpt-4-turbo
  temperature: 0.3,
  // ...other settings...
};
```

## Adding New Configuration

If you need to add new configuration values:

1. Add them to the appropriate section in `convex/config.ts`
2. Import the configuration in the file where you need to use it
3. Use the imported configuration values instead of hardcoded ones

Example:

```typescript
// In your file
import { openai as openaiConfig } from "../../config";

// Use the configuration
const response = await openai.chat.completions.create({
  model: openaiConfig.model,
  // ...other settings...
});
``` 


// File Path: convex/convex.config.ts

import { defineApp } from "convex/server";
import workflow from "@convex-dev/workflow/convex.config";

const app = defineApp();
app.use(workflow);

export default app;


// File Path: convex/files/mutations.ts

// convex/files/mutations.ts
import { mutation } from "../_generated/server";

// Public mutation: Called by the client to get a URL to upload a file *to*.
export const generateUploadUrl = mutation({
  handler: async (ctx) => {
    try {
      const uploadUrl = await ctx.storage.generateUploadUrl();
      console.log("Generated upload URL.");
      return uploadUrl;
    } catch {
      throw new Error("Could not create upload URL, please try again later.");
    }
  

  },
});


// File Path: convex/files/queries.ts

// convex/files/queries.ts
import { query } from "../_generated/server";
import { v } from "convex/values";
// Query to get a short-lived downloadable URL for a file stored in Convex storage.
export const getFileDownloadUrl = query({
  args: {
    fileId: v.string(), 
    
  },
  handler: async (ctx, args) => {
   

    try {
     
      const url = await ctx.storage.getUrl(args.fileId); 
      if (!url) {
           console.warn(`Could not generate download URL for fileId: ${args.fileId}. File might not exist.`);
           throw new Error("Unable to generate download URL right now.");
      }
      return url; 
    } catch (error) {
        console.error(`Error generating download URL for fileId ${args.fileId}:`, error);
        throw new Error("Failed to generate download URL."); 
    }
  },
});


// File Path: convex/http.ts

import { httpRouter } from "convex/server";
import { cleanHandler, cleanPageHandler } from "./api";

const http = httpRouter();


http.route({
  path: "/clean",
  method: "POST",
  handler: cleanHandler
});
http.route({
  path: "/clean",
  method: "OPTIONS",
  handler: cleanHandler   // httpAction will catch OPTIONS itself
});

http.route({
  path: "/cleanPage",
  method: "POST",
  handler: cleanPageHandler
});
http.route({
  path: "/cleanPage",
  method: "OPTIONS",
  handler: cleanPageHandler   // httpAction will catch OPTIONS itself
});

export default http;


// File Path: convex/ingest/ingest.ts

import { v } from "convex/values";
import { action, internalAction, internalMutation, internalQuery } from "../_generated/server";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { asyncMap } from "modern-async";
import { internal } from "../_generated/api";
import { openai } from "@ai-sdk/openai";
import { embedMany } from "ai";
import { embedding as embeddingConfig } from "../config";
import { Id } from "../_generated/dataModel";

export const createChunks = internalMutation({
    args: {
        pdfId: v.id("pdfs"),
    },
    handler: async (ctx, arg) => {
        const pdf = await ctx.db.get(arg.pdfId);
        if (!pdf) {
            throw new Error("PDF not found");
        }
        console.log("Creating chunks for PDF:", pdf._id);
        
        const geminiTextId = await ctx.db
        .query("openaiOcrResults")
        .withIndex("by_pdf_id", q => 
            q.eq("pdfId", arg.pdfId))
        .first();

        if (!geminiTextId) {
            throw new Error("No transcription text found for PDF");
        }

        const splitter = RecursiveCharacterTextSplitter.fromLanguage("markdown", {
            chunkSize: embeddingConfig.chunking.chunkSize,
            chunkOverlap: embeddingConfig.chunking.chunkOverlap,
        });
        const chunks = await splitter.splitText(geminiTextId.cleanedText);
        await asyncMap(chunks, async (chunk) => {
        await ctx.db.insert("chunks", {
            pdfId: arg.pdfId,
                text: chunk,
                embeddingId: null,
            });

         });
    }
});

export async function embedTexts(texts: string[]) {
    if (texts.length === 0) return [];

    const {embeddings} = await embedMany({
        model: openai.embedding(embeddingConfig.model),
        values: texts,
    })
    return embeddings
}

  export const chunksNeedingEmbedding = internalQuery({
    args:{pdfId: v.id("pdfs")},
    handler: async (ctx, args) => {
      const chunks = await ctx.db
        .query("chunks")
        .withIndex("byPdfId", (q) => q.eq("pdfId", args.pdfId))
        .filter((q) => q.eq(q.field("embeddingId"), null))
        .collect();
      return chunks;
    }
  });

export const embedList = internalAction({
    args: {
        documentIds: v.array(v.id("pdfs")),
    },
    handler: async (ctx, { documentIds }) => {
        // Get all chunks needing embedding, with their associated PDF IDs
        type ChunkWithPdfId = {
            _id: Id<"chunks">;
            pdfId: Id<"pdfs">;
            text: string;
            embeddingId: Id<"embeddings"> | null;
        };
        
        const chunksWithPdfIds: ChunkWithPdfId[] = [];
        for (const pdfId of documentIds) {
            const chunks = await ctx.runQuery(internal.ingest.ingest.chunksNeedingEmbedding, { pdfId });
            // Add pdfId to each chunk object for tracking
            chunksWithPdfIds.push(...chunks.map(chunk => ({ ...chunk, pdfId })));
        }
        
        console.log("Embedding chunks:", chunksWithPdfIds);

        // Only process if we have chunks
        if (chunksWithPdfIds.length === 0) return;

        // Get embeddings for all chunk texts
        const embeddings = await embedTexts(chunksWithPdfIds.map(chunk => chunk.text));
        
        // Save embeddings with their correct chunk and PDF IDs
        await asyncMap(embeddings, async (embedding, i) => {
            const { _id: chunkId, pdfId } = chunksWithPdfIds[i];
            await ctx.runMutation(internal.ingest.ingest.addEmbedding, { 
                chunkId, 
                embedding, 
                pdfId 
            });
        });
    },
});

export const addEmbedding = internalMutation({
    args: {
        chunkId: v.id("chunks"),
        embedding: v.array(v.number()),
        pdfId: v.id("pdfs"),
    },
    handler: async (ctx, args) => {
        // Get the chunk to check if it already has an embedding
        const chunk = await ctx.db.get(args.chunkId);
        if (!chunk) {
            console.error("Chunk not found:", args.chunkId);
            return;
        }
        
        // Skip if the chunk already has an embedding
        if (chunk.embeddingId !== null) {
            console.log("Chunk already has embedding, skipping:", args.chunkId);
            return;
        }

        // Create the embedding
        const embeddingId = await ctx.db.insert("embeddings", {
            embedding: args.embedding,
            chunkId: args.chunkId,
            pdfId: args.pdfId,
        });
        await ctx.db.patch(args.chunkId, {embeddingId});
    },
});


export const chunkAndEmbed = action({
    args:{pdfId: v.id("pdfs")},
    handler: async (ctx,args) => {
        await ctx.runMutation(internal.ingest.ingest.createChunks, {
            pdfId: args.pdfId,
        });
        await ctx.scheduler.runAfter(0, internal.ingest.ingest.embedList, { documentIds: [args.pdfId] });
    }
})


export const getEmbedding = internalQuery({
    args: { pdfId: v.id("pdfs") },
    handler: async (ctx, args) => {
        const embedding = await ctx.db.query("embeddings").withIndex("byPdfId", (q) => q.eq("pdfId", args.pdfId)).first();
        return embedding;
    }
});



// File Path: convex/ocr/gemini/actions.ts

// convex/ocr/gemini/actions.ts
import { action, internalAction } from "../../_generated/server";
import { v } from "convex/values";
import { api, internal } from "../../_generated/api";
import { Id } from "../../_generated/dataModel";
import { createPartFromUri, GoogleGenAI, Part } from "@google/genai";
import { gemini as geminiConfig } from "../../config";
import main from "../../utils/geminiOcr";
import geminiPageOcr from "../../utils/geminiOcr";

// Define valid status types to match the schema




// Action to process a PDF using Google Gemini AI for OCR
export const processPdfWithOcr = action({
  args: {
    pdfId: v.id("pdfs"), 
  },
  handler: async (ctx, args)=> {
    try {

      const current = await ctx.runQuery(api.pdf.queries.getPdf, { pdfId: args.pdfId });
      if (!current ) {
        throw new Error("PDF must be uploaded before OCR.");
      }
      

      // 1. Update PDF status to "processing" for Gemini
      await ctx.runMutation(internal.ocr.gemini.mutations.updateOcrStatus, {
        pdfId: args.pdfId as Id<"pdfs">,
        ocrStatus: "processing",
      });
      console.log(`Gemini processing started for PDF: ${args.pdfId}`);

     

      // 3. Fetch the actual PDF file content from Convex storage
      const fileData = await ctx.storage.getUrl(current.fileId);
      if (!fileData) {
        throw new Error(`PDF file blob not found in storage for fileId: ${current.fileId}`);
      }
      console.log(fileData);

      const pdfBuffer = await fetch(fileData)
        .then((response) => response.arrayBuffer());
      // 4. Prepare the file data for the Gemini API
      const fileBlob: Blob = new Blob([pdfBuffer], { type: 'application/pdf' });

      const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
      if (!GEMINI_API_KEY) {
        throw new Error("Gemini API key (GEMINI_API_KEY) is not configured in Convex environment variables.");
      }

      const ai = new GoogleGenAI({ apiKey: GEMINI_API_KEY });
      const modelName = geminiConfig.model;

      const file = await ai.files.upload({
        file: fileBlob,
        config: {
          displayName: '.pdf',
        },
      });

      if (!file.name) {
        throw new Error("File name is not available.");
      }

      // Wait for the file to be processed.
      let getFile = await ai.files.get({ name: file.name });
      while (getFile.state === 'PROCESSING') {
        getFile = await ai.files.get({ name: file.name });
        console.log(`current file status: ${getFile.state}`);
        console.log('File is still processing, retrying in 5 seconds');

        await new Promise((resolve) => {
          setTimeout(resolve, geminiConfig.fileProcessingPollingIntervalMs);
        });
      }
      if (file.state === 'FAILED') {
        throw new Error('File processing failed.');
      }

      // 6. Create the prompt and file part
      const prompt: (string | Part)[] = [geminiConfig.prompt];

      if (file.uri && file.mimeType) {
        const fileContent = createPartFromUri(file.uri, file.mimeType);
        prompt.push(fileContent);
      }

      const response = await ai.models.generateContent({
        model: modelName,
        contents: prompt,
      });
      // 8. Extract the text from the response

      if (!response.text) {
        throw new Error("Gemini API did not return any text content.");
      }

      console.log(response.text);

      console.log(`Gemini OCR successful for PDF ${args.pdfId}. Text length: ${response.candidates?.[0]?.tokenCount}`);

      // 9. Save the extracted text and update PDF status
      await ctx.runMutation(internal.ocr.gemini.mutations.updateOcrResutls, {
        pdfId: args.pdfId,
        extractedText: response.text,
        ocrStatus: "completed",
      });

    
      // 10. Immediately trigger OpenAI cleanup without waiting for other OCR services
      console.log(`Immediately triggering OpenAI cleanup for Gemini OCR results of PDF ${args.pdfId}`);

      // 11. Return success status
      

    } catch (error: unknown) {
      console.error(`Gemini OCR failed for PDF ${args.pdfId}:`, error);

      await ctx.runMutation(internal.ocr.gemini.mutations.updateOcrStatus, {
        pdfId: args.pdfId,
        ocrStatus: "failed",
      });

    }
  },
});







// Action to process a single page with Google Gemini AI for OCR
export const processPageWithOcr = internalAction({
  args: {
    pageId: v.id("pages"),
  },
  handler: async (ctx, args): Promise<{ success: boolean; pageId: Id<"pages">; provider: string }> => {
    try {
      // Get the page details
      const page = await ctx.runQuery(api.pdf.queries.getPdfPage, { pageId: args.pageId });
      if (!page) {
        throw new Error(`Page not found for ID: ${args.pageId}`);
      }

      // Update the page OCR status to "processing"
      await ctx.runMutation(internal.ocr.gemini.mutations.updatePageOcrStatus, {
        pageId: args.pageId,
        ocrStatus: "processing",
      });
      
      console.log(`Gemini processing started for page: ${args.pageId} (page ${page.pageNumber})`);

      const fileId = page.fileId;

      // Fetch the page file content from Convex storage
      const fileUrl = await ctx.storage.getUrl(fileId);
      
      if (!fileUrl) {
        throw new Error(`Page file not found in storage for fileId: ${page.fileId}`);
      }

     

      

      // Generate content with retry
      const response = await geminiPageOcr(fileUrl);
      console.log("Response from Gemini: ", response);

      if (!response.text) {
        throw new Error("Gemini API did not return any text content.");
      }

      console.log(`Gemini OCR successful for page ${args.pageId}. Text length: ${response.text.length}`);

      // Save the extracted text and update page OCR status
      await ctx.runMutation(internal.ocr.gemini.mutations.updatePageOcrResults, {
        pageId: args.pageId,
        extractedText: response.text,
        ocrStatus: "completed",
      });

      // Later in Sprint 5, we'll immediately trigger OpenAI cleanup here
      
      return { 
        success: true, 
        pageId: args.pageId,
        provider: "gemini",
      };
    } catch (error) {
      console.error(`Gemini OCR failed for page ${args.pageId}:`, error);

      // Update status to failed
      await ctx.runMutation(internal.ocr.gemini.mutations.updatePageOcrStatus, {
        pageId: args.pageId,
        ocrStatus: "failed",
      });

      throw error;
    }
  },
});


// File Path: convex/ocr/gemini/mutations.ts

// convex/ocr/gemini/mutations.ts
import { internalMutation } from "../../_generated/server";
import { v } from "convex/values";


export const updateOcrStatus = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    ocrStatus: v.union(v.literal("processing"), v.literal("failed")),
  },
  handler: async (ctx, args) => {
    const [row] = await ctx.db
      .query("geminiOcrResults")
      .withIndex("by_pdf_id", q => q.eq("pdfId", args.pdfId))
      .collect();
    if (row) {
      // update it
      await ctx.db.patch(row._id, {
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    } else {
      // or insert a new one
      await ctx.db.insert("geminiOcrResults", {
        pdfId: args.pdfId,
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    }
  },
});


export const updateOcrResutls = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    extractedText: v.string(),
    ocrStatus: v.string(),
  },
  handler: async (ctx, args): Promise<void> => {

    const [row] = await ctx.db
      .query("geminiOcrResults")
      .withIndex("by_pdf_id", q => q.eq("pdfId", args.pdfId))
      .collect();

    if (row) {
    await ctx.db.patch(row._id, {
      extractedText: args.extractedText,
      ocrStatus: "completed",
    });
    } else {
      throw new Error("Gemini OCR results not found for PDF ID: " + args.pdfId);
    }
  },
});

// convex/ocr/gemini/mutations.ts - Add to existing file

export const updatePageOcrStatus = internalMutation({
  args: {
    pageId: v.id("pages"),
    ocrStatus: v.union(v.literal("processing"), v.literal("failed")),
  },
  handler: async (ctx, args): Promise<void> => {
    const row = await ctx.db
      .query("geminiPageOcr")
      .withIndex("by_page_id", q => q.eq("pageId", args.pageId))
      .first();
      
    if (row) {
      // update existing row
      await ctx.db.patch(row._id, {
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    } else {
      // insert a new row
      await ctx.db.insert("geminiPageOcr", {
        pageId: args.pageId,
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    }
  },
});

export const updatePageOcrResults = internalMutation({
  args: {
    pageId: v.id("pages"),
    extractedText: v.string(),
    ocrStatus: v.string(),
  },
  handler: async (ctx, args): Promise<void> => {
    const row = await ctx.db
      .query("geminiPageOcr")
      .withIndex("by_page_id", q => q.eq("pageId", args.pageId))
      .first();

    if (row) {
      await ctx.db.patch(row._id, {
        extractedText: args.extractedText,
        ocrStatus: "completed",
        processedAt: Date.now(),
      });
    } else {
      // In case the row doesn't exist yet
      await ctx.db.insert("geminiPageOcr", {
        pageId: args.pageId,
        extractedText: args.extractedText,
        ocrStatus: "completed",
        processedAt: Date.now(),
      });
    }
  },
});








  


// File Path: convex/ocr/gemini/queries.ts

// convex/ocr/gemini/queries.ts
import { query } from "../../_generated/server";
import { v } from "convex/values";

// Get Gemini OCR results specifically for a given PDF ID
export const getOcrResults = query({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args) => {
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {
      
      console.warn(`PDF not found in gemini/getOcrResults query for ID: ${args.pdfId}`);
      return null; 
    }


    const ocrResults = await ctx.db
      .query("geminiOcrResults")
      .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
      .first(); 

    return {
      pdf, 
      ocrResults, 
    };
  },
});


export const getOcrStatus = query({
  args: {
    pdfId: v.id("geminiOcrResults"),
  },
  handler: async (ctx, args) => {
    const ocrResults = await ctx.db.get(args.pdfId);
    if (!ocrResults) {
     throw new Error("PDF not found in Gemini OCR for ID: ${args.pdfId}");
    }
    return {ocrStatus: ocrResults.ocrStatus};
  },

});

export const getOcrByPdfId = query({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args) => {
    return  await ctx.db
    .query("geminiOcrResults")
    .withIndex("by_pdf_id", q => q.eq("pdfId", args.pdfId))
    .collect();
  }
})


export const getPageOcrResults = query({
  args: {
    pageId: v.id("pages"),
  },
  handler: async (ctx, args) => {
    const page = await ctx.db.get(args.pageId);
    if (!page) {
      console.warn(`Page not found in gemini/getPageOcrResults query for ID: ${args.pageId}`);
      return null;
    }

    const ocrResults = await ctx.db
      .query("geminiPageOcr")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .first();

    return {
      page,
      ocrResults,
    };
  },
});

export const getPageOcrStatus = query({
  args: {
    pageId: v.id("pages"),
  },
  handler: async (ctx, args) => {
    const ocrResults = await ctx.db
      .query("geminiPageOcr")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .first();
      
    if (!ocrResults) {
      return { ocrStatus: null };
    }
    
    return { ocrStatus: ocrResults.ocrStatus };
  },
});


// File Path: convex/ocr/openai/actions.ts

// convex/ocr/openai/actions.ts - Create new file or add to existing

import { internalAction } from "../../_generated/server";
import { v } from "convex/values";
import { internal } from "../../_generated/api";

export const cleanPage = internalAction({
  args: {
    pageId: v.id("pages"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  },
  handler: async (ctx, args) => {
    const { pageId, source } = args;
    
    try {
      // Mark as started
      await ctx.runMutation(internal.ocr.openai.mutations.updatePageCleaningStatus, { 
        pageId, 
        source, 
        cleaningStatus: "started" 
      });
      
      // Get the base URL for our HTTP endpoint
      const HTTP_BASE = process.env.CONVEX_SITE_URL;
      if (!HTTP_BASE) {
        throw new Error("Missing CONVEX_SITE_URL environment variable");
      }
      
      // Call the /cleanPage HTTP endpoint
      const res = await fetch(`${HTTP_BASE}/cleanPage`, {
        method: "POST",
        headers: { 
          "Content-Type": "application/json",
        },
        body: JSON.stringify({ pageId, source }),
      });
      
      if (!res.ok) {
        const errorText = await res.text();
        throw new Error(`cleanPage HTTP failed: ${res.status} - ${errorText}`);
      }
      
      // Drain the stream to ensure completion
      await res.text();
      
      console.log(`Successfully cleaned page ${pageId} with ${source} OCR via HTTP`);
      
      return {
        success: true,
        pageId,
        source
      };
    } catch (error) {
      console.error(`Error cleaning page ${pageId} with ${source} OCR:`, error);
      throw error;
    }
  },
});


// File Path: convex/ocr/openai/mutations.ts

import { internalMutation } from "../../_generated/server";
import { v } from "convex/values";

export const saveCleanedResults = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    cleanedText: v.string(),
    cleaningStatus: v.literal("completed"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  },
  handler: async (ctx, args) => {

    
        // Insert new record
        // patch the results with index pdfId and source
        const existingJob = await ctx.db.query("openaiOcrResults")
        .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
        .filter((q) => q.eq(q.field("source"), args.source)).first();

        if (existingJob) {
          console.log("Patching existing record");
          await ctx.db.patch(existingJob._id, {
            pdfId: args.pdfId,
            cleanedText: args.cleanedText,
            cleaningStatus: args.cleaningStatus,
            processedAt: Date.now(),
          });
          
        }
        else {
          console.log("Inserting new record");
          await ctx.db.insert("openaiOcrResults", {
            pdfId: args.pdfId,
            cleanedText: args.cleanedText,
            cleaningStatus: args.cleaningStatus,
            processedAt: Date.now(),
            source: args.source,
          });
        }
        
        

  },
}); 


export const updateCleanedStatus = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    cleaningStatus: v.literal("started"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
    cleanedText: v.string(),
  },
  handler: async (ctx, args) => {
    // Check if we already have results for this PDF
    const pdfJob = await ctx.db.get(args.pdfId);
    if (!pdfJob) {
        throw new Error("PDF is not ready for cleaning");
    }

    const existingJob = await ctx.db.query("openaiOcrResults")
    .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
    .filter((q) => q.eq(q.field("source"), args.source)).first();

    if (existingJob) {
      await ctx.db.patch(existingJob._id, {
        pdfId: args.pdfId,
        cleaningStatus: args.cleaningStatus,
        source: args.source,
        processedAt: Date.now(),
      });
    }


    else {
      await ctx.db.insert("openaiOcrResults", {
        pdfId: args.pdfId,
        cleaningStatus: args.cleaningStatus,
        source: args.source,
        processedAt: Date.now(),
        cleanedText: "",
      });
    }
    }

        
  }); 





  // convex/ocr/openai/mutations.ts - Add to existing file

export const updatePageCleaningStatus = internalMutation({
  args: {
    pageId: v.id("pages"),
    cleaningStatus: v.union(v.literal("started"), v.literal("completed")),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
    cleanedText: v.optional(v.string()),
  },
  handler: async (ctx, args) => {
    // Check if we already have results for this page
    const page = await ctx.db.get(args.pageId);
    if (!page) {
      throw new Error("Page not found");
    }

    const existingCleaned = await ctx.db.query("openaiCleanedPage")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .filter((q) => q.eq(q.field("source"), args.source))
      .first();

    if (existingCleaned) {
      const update: any = {
        cleaningStatus: args.cleaningStatus,
        processedAt: Date.now(),
      };
      
      if (args.cleanedText !== undefined) {
        update.cleanedText = args.cleanedText;
      }
      
      await ctx.db.patch(existingCleaned._id, update);
    } else {
      const insert: any = {
        pageId: args.pageId,
        cleaningStatus: args.cleaningStatus,
        source: args.source,
        processedAt: Date.now(),
        cleanedText: args.cleanedText || "",
      };
      
      await ctx.db.insert("openaiCleanedPage", insert);
    }
  },
});

export const savePageCleanedResults = internalMutation({
  args: {
    pageId: v.id("pages"),
    cleanedText: v.string(),
    cleaningStatus: v.literal("completed"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  },
  handler: async (ctx, args) => {
    const existingJob = await ctx.db.query("openaiCleanedPage")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .filter((q) => q.eq(q.field("source"), args.source))
      .first();

    if (existingJob) {
      await ctx.db.patch(existingJob._id, {
        cleanedText: args.cleanedText,
        cleaningStatus: args.cleaningStatus,
        processedAt: Date.now(),
      });
    } else {
      await ctx.db.insert("openaiCleanedPage", {
        pageId: args.pageId,
        cleanedText: args.cleanedText,
        cleaningStatus: args.cleaningStatus,
        processedAt: Date.now(),
        source: args.source,
      });
    }
  },
});

// convex/ocr/openai/mutations.ts (update the startPageCleaning function)
export const startPageCleaning = internalMutation({
  args: { 
    pageId: v.id("pages"), 
    source: v.union(v.literal("gemini"), v.literal("replicate"))
  },
  handler: async (ctx, { pageId, source }) => {
    const existing = await ctx.db
      .query("openaiCleanedPage")
      .withIndex("by_page_source", q => 
        q.eq("pageId", pageId).eq("source", source))
      .unique();
    
    // Change this condition to handle the schema type
    if (existing && existing.cleaningStatus === "completed") {
      return "completed";
    }
    
    if (existing) {
      await ctx.db.patch(existing._id, { cleaningStatus: "started" }); // Use "started" instead of "processing"
    } else {
      await ctx.db.insert("openaiCleanedPage", {
        pageId,
        source,
        cleaningStatus: "started", // Use "started" instead of "processing"
        cleanedText: "",
        processedAt: Date.now(),
      });
    }
    
    return "started";
  },
});


// File Path: convex/ocr/openai/queries.ts

import { query } from "../../_generated/server";
import { v } from "convex/values";

// Get OpenAI cleaned OCR results for a given PDF
export const getCleanedResults = query({
  args: {
    pdfId: v.id("pdfs"),
    source: v.optional(v.union(v.literal("gemini"), v.literal("replicate"))),
  },
  handler: async (ctx, args) => {
    // Get the PDF document
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {
      console.warn(`PDF not found in openai/getCleanedResults query for ID: ${args.pdfId}`);
      return null;
    }

    // Build the query
    const [ocrResults]  = await ctx.db
      .query("openaiOcrResults")
      .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
      .collect();

    const cleanedResults = ocrResults.cleanedText;



    // Return structured result
    return {
      cleanedResults,
    };
  },
}); 

export const getCleanedId = query({
  args: {
    pdfId: v.id("pdfs"),
    source: v.optional(v.union(v.literal("gemini"), v.literal("replicate"))),
  },
  handler: async (ctx, args) => {
    // Get the PDF document
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {
      console.warn(`PDF not found in openai/getCleanedResults query for ID: ${args.pdfId}`);
      return null;
    }

  
    return await ctx.db
    .query("openaiOcrResults")
    .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
    .filter((q) => q.eq(q.field("source"), args.source))
    .collect();
  },
}); 







// convex/ocr/openai/queries.ts - Add to existing file

export const getPageCleanedResults = query({
  args: {
    pageId: v.id("pages"),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  },
  handler: async (ctx, args) => {
    // Get the page
    const page = await ctx.db.get(args.pageId);
    if (!page) {
      console.warn(`Page not found in openai/getPageCleanedResults query for ID: ${args.pageId}`);
      return null;
    }

    // Query for cleaned results
    const cleanedResult = await ctx.db
      .query("openaiCleanedPage")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .filter((q) => q.eq(q.field("source"), args.source))
      .first();

    if (!cleanedResult) {
      return { page, cleanedText: null, cleaningStatus: null };
    }

    return {
      page,
      cleanedText: cleanedResult.cleanedText,
      cleaningStatus: cleanedResult.cleaningStatus,
    };
  },
});


// File Path: convex/ocr/replicate/actions.ts

// convex/ocr/replicate/actions.ts
import { action, internalAction } from "../../_generated/server";
import { v } from "convex/values";
import { api, internal } from "../../_generated/api";
import Replicate from "replicate";
import { Id } from "../../_generated/dataModel";
import { replicate as replicateConfig } from "../../config";
import { runWithRetry } from "../../utils/retry";

/* ------------------------------------------------------------------ *
 * 1. Helper: merge *all* chunks returned by lucataco/olmocr-7b
 * ------------------------------------------------------------------ */
function extractOCRText(replicateOutput: unknown): string {
  /* normalise to an array of stringified chunks */
  const chunks: string[] = (() => {
    if (Array.isArray(replicateOutput)) return replicateOutput.map(String);
    if (typeof replicateOutput === "string") return [replicateOutput];
    if (
      replicateOutput &&
      typeof replicateOutput === "object" &&
      "output" in replicateOutput
    ) {
      const out = (replicateOutput as any).output;
      return Array.isArray(out) ? out.map(String) : [String(out)];
    }
    return [JSON.stringify(replicateOutput)];
  })();

  /* pull natural_text (or best effort) out of every chunk */
  const texts = chunks.map((chunk) => {
    try {
      const obj = JSON.parse(chunk);
      if (obj && typeof obj.natural_text === "string") return obj.natural_text;
    } catch {
      /* not JSON – fall through */
    }
    const m = chunk.match(/natural_text["']\s*:\s*["']([^"']+)["']/);
    return m ? m[1].replace(/\\n/g, "\n").replace(/\\"/g, '"') : chunk;
  });

  return texts.join("\n");
}

const replicate = new Replicate({ auth: process.env.REPLICATE_API_TOKEN });

/* ------------------------------------------------------------------ *
 * 2. Whole-PDF OCR (unchanged except for chunk fix + token limit bump)
 * ------------------------------------------------------------------ */
export const processPdfWithOcr = action({
  args: { pdfId: v.id("pdfs") },
  handler: async (ctx, args) => {
    try {
      const current = await ctx.runQuery(api.pdf.queries.getPdf, {
        pdfId: args.pdfId,
      });
      if (!current) throw new Error("PDF must be uploaded before OCR.");

      await ctx.runMutation(internal.ocr.replicate.mutations.updateOcrStatus, {
        pdfId: args.pdfId as Id<"pdfs">,
        ocrStatus: "processing",
      });

      const fileData = await ctx.storage.getUrl(current.fileId);
      if (!fileData)
        throw new Error(
          `PDF blob not found in storage for fileId: ${current.fileId}`,
        );

      console.log(
        `Processing ${current.pageCount} pages of PDF ${args.pdfId} via ${replicateConfig.model}`,
      );

      /* ---------- helper to OCR a single page ---------- */
      const processPage = async (pageNumber: number) => {
        const input = {
          pdf: fileData,
          page_number: 1,
          max_new_tokens:
            1024, // bump from 1024
          temperature: replicateConfig.temperature ?? 0.1,
        };

        const pageOutput = await runWithRetry({
          operation: () =>
            replicate.run(
              `${replicateConfig.model}:${replicateConfig.modelVersion}` as `${string}/${string}:${string}`,
              { input },
            ),
          maxRetries: replicateConfig.maxRetries,
          initialDelayMs: replicateConfig.retryDelayMs,
        });

        const text = extractOCRText(pageOutput);
        console.log(
          `✓ page ${pageNumber} – ${text.length.toLocaleString()} chars`,
        );
        return { pageNumber, text };
      };

      /* ---------- batched concurrency ---------- */
      const pageResults = [];
      for (let i = 0; i < current.pageCount; i += replicateConfig.batchSize) {
        const batch = Array.from(
          { length: Math.min(replicateConfig.batchSize, current.pageCount - i) },
          (_, j) => processPage(i + j + 1),
        );
        pageResults.push(...(await Promise.all(batch)));
      }

      /* ---------- aggregate + store ---------- */
      pageResults.sort((a, b) => a.pageNumber - b.pageNumber);
      const aggregatedText = pageResults
        .map((p) => `--- PAGE ${p.pageNumber} ---\n${p.text}`)
        .join("\n\n");

      await ctx.runMutation(internal.ocr.replicate.mutations.updateOcrResutls, {
        pdfId: args.pdfId,
        extractedText: aggregatedText,
        ocrStatus: "completed",
      });

      console.log(
        `Replicate OCR finished for PDF ${args.pdfId} (${aggregatedText.length.toLocaleString()} chars total)`,
      );
    } catch (error) {
      console.error(`Replicate OCR failed for PDF ${args.pdfId}:`, error);
      await ctx.runMutation(internal.ocr.replicate.mutations.updateOcrStatus, {
        pdfId: args.pdfId,
        ocrStatus: "failed",
      });
      throw error;
    }
  },
});

/* ------------------------------------------------------------------ *
 * 3. Single-page OCR fix – use real page number + token bump
 * ------------------------------------------------------------------ */
export const processPageWithOcr = internalAction({
  args: { pageId: v.id("pages") },
  handler: async (
    ctx,
    args,
  ): Promise<{ success: boolean; pageId: Id<"pages">; provider: string }> => {
    try {
      const page = await ctx.runQuery(api.pdf.queries.getPdfPage, {
        pageId: args.pageId,
      });
      if (!page) throw new Error(`Page not found: ${args.pageId}`);

      await ctx.runMutation(
        internal.ocr.replicate.mutations.updatePageOcrStatus,
        { pageId: args.pageId, ocrStatus: "processing" },
      );

      const fileUrl = await ctx.storage.getUrl(page.fileId);
      if (!fileUrl) throw new Error(`File not found: ${page.fileId}`);

      const input = {
        pdf: fileUrl,
        page_number: 1, // ← FIXED
        max_new_tokens: 1024, 
      };

      const pageOutput = await runWithRetry({
        operation: () =>
          replicate.run(
            `${replicateConfig.model}:${replicateConfig.modelVersion}` as `${string}/${string}:${string}`,
            { input },
          ),
        maxRetries: replicateConfig.maxRetries,
        initialDelayMs: replicateConfig.retryDelayMs,
      });

      const extractedText = extractOCRText(pageOutput);

      await ctx.runMutation(
        internal.ocr.replicate.mutations.updatePageOcrResults,
        {
          pageId: args.pageId,
          extractedText,
          ocrStatus: "completed",
        },
      );

      console.log(
        `Replicate OCR done for page ${args.pageId} – ${extractedText.length.toLocaleString()} chars`,
      );

      return { success: true, pageId: args.pageId, provider: "replicate" };
    } catch (error) {
      console.error(`Replicate OCR failed for page ${args.pageId}:`, error);
      await ctx.runMutation(
        internal.ocr.replicate.mutations.updatePageOcrStatus,
        { pageId: args.pageId, ocrStatus: "failed" },
      );
      throw error;
    }
  },
});



// File Path: convex/ocr/replicate/mutations.ts

// convex/ocr/replicate/mutations.ts
import { internalMutation } from "../../_generated/server";
import { v } from "convex/values";


export const updateOcrStatus = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    ocrStatus: v.union(v.literal("processing"), v.literal("failed")),
  },
  handler: async (ctx, args) => {
    const [row] = await ctx.db
      .query("replicateOcrResults")
      .withIndex("by_pdf_id", q => q.eq("pdfId", args.pdfId))
      .collect();
    if (row) {
      // update it
      await ctx.db.patch(row._id, {
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    } else {
      // or insert a new one
      await ctx.db.insert("replicateOcrResults", {
        pdfId: args.pdfId,
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    }
  },
});


export const updateOcrResutls = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    extractedText: v.string(),
    ocrStatus: v.string(),
  },
  handler: async (ctx, args) => {

    const [row] = await ctx.db
      .query("replicateOcrResults")
      .withIndex("by_pdf_id", q => q.eq("pdfId", args.pdfId))
      .collect();

    if (row) {
    await ctx.db.patch(row._id, {
      extractedText: args.extractedText,
      ocrStatus: "completed",
    });
    } else {
      throw new Error("Replicate OCR results not found for PDF ID: " + args.pdfId);
    }
  },
});





// convex/ocr/replicate/mutations.ts - Add to existing file

export const updatePageOcrStatus = internalMutation({
  args: {
    pageId: v.id("pages"),
    ocrStatus: v.union(v.literal("processing"), v.literal("failed")),
  },
  handler: async (ctx, args): Promise<void> => {
    const row = await ctx.db
      .query("replicatePageOcr")
      .withIndex("by_page_id", q => q.eq("pageId", args.pageId))
      .first();
      
    if (row) {
      // update existing row
      await ctx.db.patch(row._id, {
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    } else {
      // insert a new row
      await ctx.db.insert("replicatePageOcr", {
        pageId: args.pageId,
        ocrStatus: args.ocrStatus,
        processedAt: Date.now(),
      });
    }
  },
});

export const updatePageOcrResults = internalMutation({
  args: {
    pageId: v.id("pages"),
    extractedText: v.string(),
    ocrStatus: v.string(),
  },
  handler: async (ctx, args): Promise<void> => {
    const row = await ctx.db
      .query("replicatePageOcr")
      .withIndex("by_page_id", q => q.eq("pageId", args.pageId))
      .first();

    if (row) {
      await ctx.db.patch(row._id, {
        extractedText: args.extractedText,
        ocrStatus: "completed",
        processedAt: Date.now(),
      });
    } else {
      // In case the row doesn't exist yet
      await ctx.db.insert("replicatePageOcr", {
        pageId: args.pageId,
        extractedText: args.extractedText,
        ocrStatus: "completed",
        processedAt: Date.now(),
      });
    }
  },
});


// File Path: convex/ocr/replicate/queries.ts

// convex/ocr/replicate/queries.ts
import { query } from "../../_generated/server";
import { v } from "convex/values";

// Get Gemini OCR results specifically for a given PDF ID
export const getOcrResults = query({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args) => {
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {
      
      console.warn(`PDF not found in Replicate/getOcrResults query for ID: ${args.pdfId}`);
      return null; 
    }


    const ocrResults = await ctx.db
      .query("replicateOcrResults")
      .withIndex("by_pdf_id", (q) => q.eq("pdfId", args.pdfId))
      .first(); 

    return {
      pdf, 
      ocrResults, 
    };
  },
});


export const getOcrStatus = query({
  args: {
    pdfId: v.id("replicateOcrResults"),
  },
  handler: async (ctx, args) => {
    const ocrResults = await ctx.db.get(args.pdfId);
    if (!ocrResults) {
     throw new Error("PDF not found in Replicate OCR for ID: ${args.pdfId}");
    }
    return {ocrStatus: ocrResults.ocrStatus};
  },

  
});


export const getOcrByPdfId = query({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args) => {
    return  await ctx.db
    .query("replicateOcrResults")
    .withIndex("by_pdf_id", q => q.eq("pdfId", args.pdfId))
    .collect();
  }
})


export const getPageOcrResults = query({
  args: {
    pageId: v.id("pages"),
  },
  handler: async (ctx, args) => {
    const page = await ctx.db.get(args.pageId);
    if (!page) {
      console.warn(`Page not found in gemini/getPageOcrResults query for ID: ${args.pageId}`);
      return null;
    }

    const ocrResults = await ctx.db
      .query("replicatePageOcr")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .first();

    return {
      page,
      ocrResults,
    };
  },
});


// File Path: convex/pdf/actions.ts

// convex/pdf/actions.ts (new file)
import { internalAction } from "../_generated/server";
import { v } from "convex/values";
import { api, internal } from "../_generated/api";
import { splitPdf } from "../utils/pdfSplitter";
import { Id } from "../_generated/dataModel";

export const splitPdfIntoPages = internalAction({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args): Promise<Id<"pages">[]> => {
    // Skip if feature flag is not enabled


    try {
      // Get the PDF data
      const pdf = await ctx.runQuery(api.pdf.queries.getPdf, { pdfId: args.pdfId });
      if (!pdf) {
        throw new Error(`PDF not found for ID: ${args.pdfId}`);
      }

      // Fetch the PDF file
      const fileUrl = await ctx.storage.getUrl(pdf.fileId);
      
      
      if (!fileUrl) {
        throw new Error(`Could not get file URL for fileId: ${pdf.fileId}`);
      }

      // Download the PDF
      const response = await fetch(fileUrl);
      const pdfBuffer = await response.arrayBuffer();
      
      // Split into pages
      const pageBlobs = await splitPdf(pdfBuffer);
      console.log(`Split PDF into ${pageBlobs.length} pages`);
      
      // Store each page and create database entries
      const pageIds = [];
      
      for (let i = 0; i < pageBlobs.length; i++) {
        const pageNumber = i + 1;
        const pageBlob = pageBlobs[i];
        
        // Store the page in Convex storage
        const pageFileId = await ctx.storage.store(pageBlob);
        
        // Insert page record
        const pageId: Id<"pages"> = await ctx.runMutation(internal.pdf.mutations.savePdfPage, {
          pdfId: args.pdfId,
          pageNumber, 
          fileId: pageFileId,
          // Optional width/height could be added here if extracted
        });
        
        pageIds.push(pageId);
      }
      
      // Update the pageCount in the parent PDF if needed
      await ctx.runMutation(internal.pdf.mutations.updatePdfPageCount, {
        pdfId: args.pdfId,
        pageCount: pageBlobs.length
      });
      console.log(`Updated pageCount for PDF ${args.pdfId} to ${pageBlobs.length}`);
      console.log(`Page IDs: ${pageIds}`);
      return pageIds;
    } catch (error) {
      console.error(`Error in splitPdfIntoPages for PDF ${args.pdfId}:`, error);
      throw error;
    }
  },
});


// File Path: convex/pdf/mutations.ts

// convex/pdf/mutations.ts
import { internal } from "../_generated/api";
import { action, internalMutation, mutation } from "../_generated/server";
import { v } from "convex/values";
import { workflow } from "../workflow";
import { Id } from "../_generated/dataModel";


// Page by page mutations
// Public mutation: Called by the client after successfully uploading a file to storage.


export const savePdfMetadata = mutation({
  args: {
    fileId: v.string(),
    filename: v.string(),
    fileSize: v.number(),
    pageCount: v.number(),
  },
  handler: async (ctx, args) => {
 

    // Insert a new document into the 'pdfs' table
    const pdfId = await ctx.db.insert("pdfs", {
      fileId: args.fileId , // Store as StorageId type in DB
      filename: args.filename,
      fileSize: args.fileSize,
      pageCount: args.pageCount,
      uploadedAt: Date.now(), 
      status: "uploaded",


    });

    console.log(`Saved PDF metadata for ${args.filename}, ID: ${pdfId}`);
    await workflow.start(
      ctx,
      internal.workflow.ocrWorkflow.ocrWorkflow,
      { pdfId }
    );
    return pdfId;
  },
});







// Add this to the existing mutations file
export const savePdfPage = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    pageNumber: v.number(),
    fileId: v.string(),
    width: v.optional(v.number()),
    height: v.optional(v.number()),
  },
  handler: async (ctx, args): Promise<Id<"pages">> => {
    return await ctx.db.insert("pages", {
      pdfId: args.pdfId,
      pageNumber: args.pageNumber,
      fileId: args.fileId,
      width: args.width,
      height: args.height,
      createdAt: Date.now(),
    });
  },
});

export const updatePdfPageCount = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    pageCount: v.number(),
  },
  handler: async (ctx, args): Promise<void> => {
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {
      throw new Error(`PDF not found for ID: ${args.pdfId}`);
    }
    
    await ctx.db.patch(args.pdfId, {
      pageCount: args.pageCount,
    });
  },
});







// File Path: convex/pdf/queries.ts

// convex/pdf/queries.ts
import { Doc } from "../_generated/dataModel";
import { query } from "../_generated/server";
import { v } from "convex/values";
import { ConvexError } from "convex/values";
import type { PdfPageInfo, OcrStatus } from "../../src/app/pdf/types";

// Get a list of all uploaded PDFs, potentially filtered and ordered.
export const getPdfList = query({
  args: {
    status: v.optional(v.string()), 
    replicateStatus: v.optional(v.string()), 
    filenameContains: v.optional(v.string()), 

  },
  handler: async (ctx, args) => {
    let pdfsQuery = ctx.db.query("pdfs");

    // Apply filters dynamically based on provided arguments
    if (args.status) {
      pdfsQuery = pdfsQuery.filter((q) => q.eq(q.field("status"), args.status));
    }
    

    return await pdfsQuery.order("desc").collect();
  },
});

// Get a single PDF document by its Convex ID (_id).
export const getPdf = query({
  args: {
    pdfId: v.id("pdfs"), 
  },
  handler: async (ctx, args): Promise<Doc<"pdfs"> | null> => {
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {

      console.warn(`PDF with ID ${args.pdfId} not found.`);
      throw new Error(`PDF with ID ${args.pdfId} not found.`);
    }
    return pdf;
  },
});


export const getPdfPages = query({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args): Promise<Doc<"pages">[]> => {
    return await ctx.db
      .query("pages")
      .withIndex("byPdfIdAndPageNumber", (q) => q.eq("pdfId", args.pdfId))
      .collect();
  },
});

export const getPdfPage = query({
  args: {
    pageId: v.id("pages"),
  },
  handler: async (ctx, args): Promise<Doc<"pages"> | null> => {
    return await ctx.db.get(args.pageId);
  },
});


export const getPageWithOcrResults = query({
  args: {
    pageId: v.id("pages"),
  },
  handler: async (ctx, args): Promise<(Doc<"pages"> & {
    geminiOcr: Doc<"geminiPageOcr"> | null;
    replicateOcr: Doc<"replicatePageOcr"> | null;
    openaiCleaned: Doc<"openaiCleanedPage">[];
  }) | null> => {
    const page = await ctx.db.get(args.pageId);
    if (!page) {
      return null;
    }

    const geminiOcr = await ctx.db
      .query("geminiPageOcr")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .first();

    const replicateOcr = await ctx.db
      .query("replicatePageOcr")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .first();

    const openaiCleaned = await ctx.db
      .query("openaiCleanedPage")
      .withIndex("by_page_id", (q) => q.eq("pageId", args.pageId))
      .collect();

    return {
      ...page,
      geminiOcr,
      replicateOcr,
      openaiCleaned,
    };
  },
});

// NEW: Get all pages for a PDF with status and snippet information
export const getPagesByPdf = query({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (ctx, args): Promise<PdfPageInfo[]> => {
    // Check if PDF exists
    const pdf = await ctx.db.get(args.pdfId);
    if (!pdf) {
      throw new ConvexError("PDF not found");
    }

    // Get all pages for this PDF, sorted by page number
    const pages = await ctx.db
      .query("pages")
      .withIndex("byPdfIdAndPageNumber", (q) => q.eq("pdfId", args.pdfId))
      .collect();

    // Map each page to PdfPageInfo
    const pageInfos: PdfPageInfo[] = await Promise.all(
      pages.map(async (page): Promise<PdfPageInfo> => {
        // Get Gemini OCR status
        const geminiOcr = await ctx.db
          .query("geminiPageOcr")
          .withIndex("by_page_id", (q) => q.eq("pageId", page._id))
          .first();
        
        // Get Replicate OCR status
        const replicateOcr = await ctx.db
          .query("replicatePageOcr")
          .withIndex("by_page_id", (q) => q.eq("pageId", page._id))
          .first();

        // Get cleaned text (prioritize OpenAI cleaned, fallback to raw OCR)
        let cleanedText: string | null = null;
        
        // First try OpenAI cleaned text
        const openaiCleaned = await ctx.db
          .query("openaiCleanedPage")
          .withIndex("by_page_id", (q) => q.eq("pageId", page._id))
          .filter((q) => q.eq(q.field("cleaningStatus"), "completed"))
          .first();
        
        if (openaiCleaned?.cleanedText) {
          cleanedText = openaiCleaned.cleanedText;
        } else {
          // Fallback to raw OCR text from either source
          if (geminiOcr?.extractedText) {
            cleanedText = geminiOcr.extractedText;
          } else if (replicateOcr?.extractedText) {
            cleanedText = replicateOcr.extractedText;
          }
        }

        // Create snippet (first 160 characters)
        let cleanedSnippet: string | null = null;
        if (cleanedText && cleanedText.length > 0) {
          cleanedSnippet = cleanedText.length > 160 
            ? `${cleanedText.slice(0, 160)}…` 
            : cleanedText;
        }

        return {
          pageId: page._id,
          pageNumber: page.pageNumber,
          geminiStatus: (geminiOcr?.ocrStatus as OcrStatus) || "pending",
          replicateStatus: (replicateOcr?.ocrStatus as OcrStatus) || "pending",
          cleanedSnippet,
        };
      })
    );

    // Return pages sorted by page number
    return pageInfos.sort((a, b) => a.pageNumber - b.pageNumber);
  },
});


// File Path: convex/performOCR.ts

// Mutation that runs the internal action and returns the OCR content
import { internalAction, mutation } from "./_generated/server";
import { internal } from "./_generated/api";
import { v } from "convex/values";
import {
    GoogleGenAI,
    createPartFromUri,
    Part
} from "@google/genai";
import { gemini as geminiConfig, ocr as ocrConfig } from "./config";


export const exposeOCR = mutation({
    args: {
        url: v.string(),
    },
    handler: async (ctx, {url}) => {
        if (!url) {
            throw new Error('URL is required');
        }
        await ctx.scheduler.runAfter(0, internal.performOCR.performOCR, {url}) 
        return 
    },
});

export const performOCR = internalAction({
    args: {
        url: v.string(),
    },
    handler: async (ctx, args) => {

        const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });
        const pdfBuffer = await fetch(args.url)
            .then((response) => response.arrayBuffer());

        // Use the ArrayBuffer directly, no need to convert to Buffer
        const fileBlob = new Blob([pdfBuffer], { type: 'application/pdf' });

        const file = await ai.files.upload({
            file: fileBlob,
            config: {
                displayName: args.url,
            },
        });

        // Wait for the file to be processed.
        if (!file.name) {
            throw new Error('File name is undefined');
        }

        let getFile = await ai.files.get({ name: file.name });
        while (getFile.state === 'PROCESSING') {
            getFile = await ai.files.get({ name: file.name });
            console.log(`current file status: ${getFile.state}`);
            console.log('File is still processing, retrying in 5 seconds');
            await new Promise((resolve) => {
                setTimeout(resolve, geminiConfig.fileProcessingPollingIntervalMs);
            });
        }

        if (getFile.state === 'FAILED') {
            throw new Error('File processing failed.');
        }

        // Add the file to the contents.
        const content: (string | Part)[] = [
            ocrConfig.performOcrPrompt,
        ];

        if (file.uri && file.mimeType) {
            const fileContent = createPartFromUri(file.uri, file.mimeType);
            content.push(fileContent);
        }

        const response = await ai.models.generateContent({
            model: geminiConfig.model,
            contents: content,
        });

        return {
            text: response.text,
            url: args.url,
        };
    },
})



// File Path: convex/README.md

# Welcome to your Convex functions directory!

Write your Convex functions here.
See https://docs.convex.dev/functions for more.

A query function that takes two arguments looks like:

```ts
// functions.js
import { query } from "./_generated/server";
import { v } from "convex/values";

export const myQueryFunction = query({
  // Validators for arguments.
  args: {
    first: v.number(),
    second: v.string(),
  },

  // Function implementation.
  handler: async (ctx, args) => {
    // Read the database as many times as you need here.
    // See https://docs.convex.dev/database/reading-data.
    const documents = await ctx.db.query("tablename").collect();

    // Arguments passed from the client are properties of the args object.
    console.log(args.first, args.second);

    // Write arbitrary JavaScript here: filter, aggregate, build derived data,
    // remove non-public properties, or create new objects.
    return documents;
  },
});
```

Using this query function in a React component looks like:

```ts
const data = useQuery(api.functions.myQueryFunction, {
  first: 10,
  second: "hello",
});
```

A mutation function looks like:

```ts
// functions.js
import { mutation } from "./_generated/server";
import { v } from "convex/values";

export const myMutationFunction = mutation({
  // Validators for arguments.
  args: {
    first: v.string(),
    second: v.string(),
  },

  // Function implementation.
  handler: async (ctx, args) => {
    // Insert or modify documents in the database here.
    // Mutations can also read from the database like queries.
    // See https://docs.convex.dev/database/writing-data.
    const message = { body: args.first, author: args.second };
    const id = await ctx.db.insert("messages", message);

    // Optionally, return a value from your mutation.
    return await ctx.db.get(id);
  },
});
```

Using this mutation function in a React component looks like:

```ts
const mutation = useMutation(api.functions.myMutationFunction);
function handleButtonPress() {
  // fire and forget, the most common way to use mutations
  mutation({ first: "Hello!", second: "me" });
  // OR
  // use the result once the mutation has completed
  mutation({ first: "Hello!", second: "me" }).then((result) =>
    console.log(result),
  );
}
```

Use the Convex CLI to push your functions to a deployment. See everything
the Convex CLI can do by running `npx convex -h` in your project root
directory. To learn more, launch the docs with `npx convex docs`.



// File Path: convex/schema.ts

// convex/schema.ts
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";
import { embedding as embeddingConfig } from "./config";

export default defineSchema({
  // Stores metadata about uploaded PDF files and tracks processing status for each provider.
  pdfs: defineTable({
    fileId: v.string(), 
    filename: v.string(), 
    fileSize: v.number(), 
    pageCount: v.number(),
    uploadedAt: v.number(), 
    status: v.string(),
    processingError: v.optional(v.string()), 

  }),

  geminiOcrResults: defineTable({
    pdfId: v.id("pdfs"),
    extractedText: v.optional(v.string()),
    processedAt: v.number(),
    ocrStatus: v.union(v.literal("processing"), v.literal("completed"), v.literal("failed")),
  })
  .index("by_pdf_id", ["pdfId"]),

  replicateOcrResults: defineTable({
    pdfId: v.id("pdfs"),
    extractedText: v.optional(v.string()),
    processedAt: v.number(),
    ocrStatus: v.union(v.literal("processing"), v.literal("completed"), v.literal("failed")),
  })
  .index("by_pdf_id", ["pdfId"]),

  openaiOcrResults: defineTable({
    pdfId: v.id("pdfs"),
    cleanedText: v.string(),
    processedAt: v.number(),
    cleaningStatus:  v.union(v.literal("started"), v.literal("completed")),
    source: v.union(v.literal("gemini"), v.literal("replicate")),
  })
  .index("by_pdf_id", ["pdfId"]),

  chunks: defineTable({
    pdfId: v.id("pdfs"),
    text: v.string(),
    embeddingId: v.union(v.id("embeddings"), v.null()),
  })
    .index("byPdfId", ["pdfId"])
    .index("byEmbeddingId", ["embeddingId"]),


embeddings: defineTable({
  embedding: v.array(v.number()),
  chunkId: v.id("chunks"),
  pdfId: v.id("pdfs"),
})
  .index("byChunkId", ["chunkId"])
  .index("byPdfId", ["pdfId"])

  .vectorIndex("byEmbedding", {
    vectorField: "embedding",
    dimensions: embeddingConfig.dimensions,
    filterFields: ["pdfId"],
  }),

  // Add to schema.ts
chatSessions: defineTable({
  sessionId: v.string(),
}),

messages: defineTable({
  sessionId: v.optional(v.string()),
  isUser: v.boolean(),
  text: v.string(),
  timestamp: v.number(),
})
.index("bySessionId", ["sessionId"]),

ragSources: defineTable({
  sessionId: v.string(),
  pdfIds: v.array(v.id("pdfs")),
})
.index("bySessionId", ["sessionId"])
.index("byPdfId", ["pdfIds"]),




// New page by page schemas

pages: defineTable({
  pdfId: v.id("pdfs"),
  pageNumber: v.number(),
  fileId: v.string(), // Convex storage ID for the page image/PDF
  width: v.optional(v.number()),
  height: v.optional(v.number()),
  createdAt: v.number(),
})
.index("byPdfId", ["pdfId"])
.index("byPdfIdAndPageNumber", ["pdfId", "pageNumber"]),

geminiPageOcr: defineTable({
  pageId: v.id("pages"),
  extractedText: v.optional(v.string()),
  ocrStatus: v.union(v.literal("processing"), v.literal("completed"), v.literal("failed")),
  processedAt: v.number(),
})
.index("by_page_id", ["pageId"]),

replicatePageOcr: defineTable({
  pageId: v.id("pages"),
  extractedText: v.optional(v.string()),
  ocrStatus: v.union(v.literal("processing"), v.literal("completed"), v.literal("failed")),
  processedAt: v.number(),
})
.index("by_page_id", ["pageId"]),

openaiCleanedPage: defineTable({
  pageId: v.id("pages"),
  cleanedText: v.string(),
  processedAt: v.number(),
  cleaningStatus: v.union(v.literal("started"), v.literal("completed")),
  source: v.union(v.literal("gemini"), v.literal("replicate")),
})
.index("by_page_id", ["pageId"])
.index("by_page_source", ["pageId", "source"]), // Add this index

});




// File Path: convex/serve/serve.ts

import { internalAction, internalMutation, internalQuery, mutation, query } from "../_generated/server";
import { Id } from "../_generated/dataModel";
import { api, internal } from "../_generated/api";
import { v } from "convex/values";
import { embedTexts } from "../ingest/ingest";
import { asyncMap } from "modern-async";
import { streamText } from 'ai';
import { openai } from "@ai-sdk/openai";

// Type definitions
interface Message {
  id?: Id<"messages">;
  isUser: boolean;
  text: string;
  sessionId?: string;
  timestamp: number;
}

interface Chunk {
  _id: Id<"chunks">;
  pdfId: Id<"pdfs">;
  text: string;
  embeddingId: Id<"embeddings"> | null;
}

// Main answer function implementing streaming with OpenAI
export const answer = internalAction({
  args: {
    sessionId: v.string(),
  },
  handler: async (ctx, { sessionId }) => {
    // Get messages and process the last user message
    const messages = await ctx.runQuery(api.serve.serve.retrieveMessages, {
      sessionId,
    }) as Message[];
    
    // If no messages, return early
    if (!messages.length) {
      console.error("No messages found for session:", sessionId);
      return;
    }
    
    const lastUserMessage = messages.at(-1)!.text;
    console.log("Processing user message:", lastUserMessage);
    
    // Create a message placeholder for the bot response
    const messageId = await ctx.runMutation(internal.serve.serve.addBotMessage, {
      sessionId,
    });

    try {
      // 1. Search for relevant documents using vector search
      const [embedding] = await embedTexts([lastUserMessage]);
      
      // Search for relevant documents
      const searchResults = await ctx.vectorSearch("embeddings", "byEmbedding", {
        vector: embedding,
        limit: 8,
      });

      if (searchResults.length === 0) {
        await ctx.runMutation(internal.serve.serve.updateBotMessage, {
          messageId,
          text: "I couldn't find any relevant information in the documents to answer your question. Could you please rephrase or ask about something covered in the uploaded documents?",
        });
        return;
      }

      // Get the relevant documents
      const relevantDocuments = await ctx.runQuery(internal.serve.serve.getChunks, {
        embeddingIds: searchResults.map((result) => result._id),
      }) as Chunk[];

      console.log(`Found ${relevantDocuments.length} relevant chunks`);
      
      // Extract and update PDF IDs
      const relevantPdfs = relevantDocuments.map((doc: Chunk) => doc.pdfId);
      const uniqueRelevantPdfs = [...new Set(relevantPdfs)];
      
      await ctx.runMutation(internal.serve.serve.updateRagSources, {
        sessionId,
        pdfIds: uniqueRelevantPdfs,
      });

      // Use OpenAI's streaming API via Vercel AI SDK
      const result = streamText({
        model: openai('gpt-4o'),
        messages: [
          {
            role: "system",
            content:
              "Answer the user question based on the provided documents " +
              "or report that the question cannot be answered based on " +
              "these documents. Keep the answer informative but brief, " +
              "do not enumerate all possibilities.",
          },
          ...relevantDocuments.map((doc: Chunk) => ({
            role: "system" as const,
            content: "Relevant document:\n\n" + doc.text,
          })),
          ...messages.map((msg: Message) => ({
            role: (msg.isUser ? "user" : "assistant") as "user" | "assistant",
            content: msg.text,
          })),
        ],
      });

      // Stream the response and update the message incrementally
      let fullText = "";
      for await (const textPart of result.textStream) {
        fullText += textPart;
        
        // Update the bot message as new text chunks arrive
        await ctx.runMutation(internal.serve.serve.updateBotMessage, {
          messageId,
          text: fullText,
        });
      }
      
      console.log("Completed streaming response");

    } catch (error) {
      console.error("Error in streaming response:", error);
      
      // Update with error message
      await ctx.runMutation(internal.serve.serve.updateBotMessage, {
        messageId,
        text: "Sorry, I encountered an error while generating a response. Please try again.",
      });
      
      throw error;
    }
  }
});

// Supporting mutation and query functions
export const updateRagSources = internalMutation({
  args: {
    sessionId: v.string(),
    pdfIds: v.array(v.id("pdfs")),
  },
  handler: async (ctx, { sessionId, pdfIds }) => {
    return await ctx.db.insert("ragSources", { sessionId, pdfIds });
  }
});

// The function that's causing the error - make it a regular query (not internal)
export const getRagSources = query({
  args: {
    sessionId: v.string(),
  },
  handler: async (ctx, { sessionId }) => {
    return await ctx.db.query("ragSources")
      .withIndex("bySessionId", (q) => q.eq("sessionId", sessionId))
      .collect();
  }
});

export const getChunks = internalQuery({
  args: {
    embeddingIds: v.array(v.id("embeddings")),
  },
  handler: async (ctx, { embeddingIds }) => {
    return await asyncMap(
      embeddingIds,
      async (embeddingId: Id<"embeddings">) =>
        (await ctx.db
          .query("chunks")
          .withIndex("byEmbeddingId", (q) => q.eq("embeddingId", embeddingId))
          .unique())!
    );
  }
});

export const addBotMessage = internalMutation({
  args: {
    sessionId: v.string(),
  },
  handler: async (ctx, { sessionId }) => {
    return await ctx.db.insert("messages", {
      isUser: false,
      text: "",
      sessionId,
      timestamp: Date.now(),
    });
  }
});

export const updateBotMessage = internalMutation({
  args: {
    messageId: v.id("messages"),
    text: v.string(),
  },
  handler: async (ctx, { messageId, text }) => {
    return await ctx.db.patch(messageId, { text });
  }
});

export const saveMessage = mutation({
  args: {
    message: v.string(),
    sessionId: v.string(),
    isUser: v.boolean(),
  },
  handler: async (ctx, { message, sessionId, isUser }) => {
     await ctx.db.insert("messages", { text: message, sessionId, isUser, timestamp: Date.now() });
     await ctx.scheduler.runAfter(0, internal.serve.serve.answer, {
      sessionId,
    });
  }
});

export const saveSessionId = mutation({
  args: {
    sessionId: v.string(),
  },
  handler: async (ctx, { sessionId }) => {
    return await ctx.db.insert("chatSessions", { sessionId });
  }
});

export const retrieveMessages = query({
  args: {
    sessionId: v.string(),
  },
  handler: async (ctx, { sessionId }) => {
    return await ctx.db.query("messages")
      .withIndex("bySessionId", (q) => q.eq("sessionId", sessionId))
      .collect();
  }
});


// File Path: convex/tsconfig.json

{
  /* This TypeScript project config describes the environment that
   * Convex functions run in and is used to typecheck them.
   * You can modify it, but some settings required to use Convex.
   */
  "compilerOptions": {
    /* These settings are not required by Convex and can be modified. */
    "allowJs": true,
    "strict": true,
    "moduleResolution": "Bundler",
    "jsx": "react-jsx",
    "skipLibCheck": true,
    "allowSyntheticDefaultImports": true,

    /* These compiler options are required by Convex */
    "target": "ESNext",
    "lib": ["ES2021", "dom"],
    "forceConsistentCasingInFileNames": true,
    "module": "ESNext",
    "isolatedModules": true,
    "noEmit": true
  },
  "include": ["./**/*"],
  "exclude": ["./_generated"]
}



// File Path: convex/utils/cleaner.ts

import { streamText } from 'ai';
import { openai } from "@ai-sdk/openai";
import { openai as openaiConfig } from "../config";

/**
 * Pure OpenAI text cleaning utility using async generator pattern.
 * Streams cleaned text chunks and returns the full text when complete.
 * 
 * @param input - Raw text to be cleaned
 * @param model - OpenAI model to use (defaults to config value)
 * @returns AsyncGenerator that yields chunks and returns full text
 */
export async function* cleanTextWithOpenAI(
  input: string,
  model: "gpt-4o-mini" | "gpt-4-turbo" = openaiConfig.streamingModel as "gpt-4o-mini"
): AsyncGenerator<string, string, void> {
  let fullText = "";
  
  try {
    const { textStream } = await streamText({
      model: openai(model),
      system: openaiConfig.systemPrompt,
      prompt: input,
      temperature: openaiConfig.temperature,
    });
    
    for await (const chunk of textStream) {
      fullText += chunk;
      yield chunk;
    }
    
    return fullText;
  } catch (error) {
    // Re-throw errors to be handled by the HTTP handlers
    throw error;
  }
}


// File Path: convex/utils/geminiOcr.ts

import { GoogleGenAI } from "@google/genai";
import { gemini } from "../config";

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

// Utility: convert ArrayBuffer → base64 without Buffer
function arrayBufferToBase64(buffer: ArrayBuffer): string {
  let binary = "";
  const bytes = new Uint8Array(buffer);
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  // `btoa` is available in the Convex V8 runtime
  return btoa(binary);
}

export default async function geminiPageOcr(pdfPageUrl: string) {
  console.log("Contacting Gemini …");

  const arrayBuffer = await fetch(pdfPageUrl).then((r) => r.arrayBuffer());
  const base64 = arrayBufferToBase64(arrayBuffer);

  const contents = [
    { text: gemini.prompt },
    {
      inlineData: {
        mimeType: "application/pdf",
        data: base64,
      },
    },
  ];

  const response = await ai.models.generateContent({
    model: gemini.model,
    contents,
  });

  console.log(response.text);
  return response;
}


// File Path: convex/utils/pdfSplitter.ts

// convex/utils/pdfSplitter.ts
import { PDFDocument } from "pdf-lib";

export async function splitPdf(pdfBuffer: ArrayBuffer): Promise<Blob[]> {
  try {
    // Load the PDF
    const pdfDoc = await PDFDocument.load(pdfBuffer);
    const pageCount = pdfDoc.getPageCount();
    console.log(`Splitting PDF with ${pageCount} pages`);
    
    // Array to hold individual page PDFs
    const pageBlobs: Blob[] = [];
    
    // Process each page
    for (let i = 0; i < pageCount; i++) {
      // Create a new document with just this page
      const newDoc = await PDFDocument.create();
      const [page] = await newDoc.copyPages(pdfDoc, [i]);
      newDoc.addPage(page);
      
      // Convert to PDF bytes
      const pdfBytes = await newDoc.save();
      
      // Convert to Blob
      const blob = new Blob([pdfBytes], { type: 'application/pdf' });
      pageBlobs.push(blob);
    }
    
    return pageBlobs;
  } catch (error) {
    console.error('Error splitting PDF:', error);
    throw new Error(`Failed to split PDF: ${error instanceof Error ? error.message : String(error)}`);
  }
}


// File Path: convex/utils/retry.ts

// convex/utils/retry.ts

/**
 * Utility for retrying operations with exponential backoff
 */
export async function runWithRetry<T>({
    operation,
    maxRetries = 5,
    initialDelayMs = 1000,
    maxDelayMs = 60000,
    onRetry,
  }: {
    operation: () => Promise<T>;
    maxRetries?: number;
    initialDelayMs?: number;
    maxDelayMs?: number;
    onRetry?: (attempt: number, error: Error, delayMs: number) => void;
  }): Promise<T> {
    let lastError: Error | null = null;
    let currentDelay = initialDelayMs;
  
    for (let attempt = 1; attempt <= maxRetries + 1; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        
        // If this was the last attempt, rethrow the error
        if (attempt > maxRetries) {
          throw new Error(`Operation failed after ${maxRetries} retries: ${lastError.message}`);
        }
        
        // Calculate next delay with exponential backoff and jitter
        const jitter = Math.random() * 0.3 + 0.85; // Between 0.85 and 1.15
        currentDelay = Math.min(currentDelay * 2 * jitter, maxDelayMs);
        
        // Call optional callback
        if (onRetry) {
          onRetry(attempt, lastError, currentDelay);
        } else {
          console.log(`Attempt ${attempt} failed: ${lastError.message}. Retrying in ${currentDelay}ms...`);
        }
        
        // Wait before next attempt
        await new Promise(resolve => setTimeout(resolve, currentDelay));
      }
    }
    
    // This should never be reached due to the rethrow above, but TypeScript needs it
    throw lastError;
  }


// File Path: convex/utils/stream.ts


// diff --git a/convex/utils/streams.ts b/convex/utils/streams.ts
export function readableStreamFromIterable<T>(
  iterable: AsyncIterable<T> | Iterable<T>
): ReadableStream<Uint8Array> {
  const encoder = new TextEncoder();
  return new ReadableStream({
    async pull(controller) {
      for await (const chunk of iterable as AsyncIterable<T>) {
        controller.enqueue(
          typeof chunk === "string" ? encoder.encode(chunk) : (chunk as any)
        );
      }
      controller.close();
    },
  });
}



// File Path: convex/workflow/concatenateWorkflow.ts

// convex/workflows/concatenateWorkflow.ts
import { workflow } from "./index";
import { v } from "convex/values";
import { api, internal } from "../_generated/api";
import { action, internalMutation } from "../_generated/server";

export const concatenateAndEmbedWorkflow = workflow.define({
  args: {
    pdfId: v.id("pdfs"),
    preferredSource: v.optional(v.union(v.literal("gemini"), v.literal("replicate"))),
    retryCount: v.optional(v.number()),
  },
  handler: async (step, { pdfId, preferredSource, retryCount = 0 }): Promise<void> => {
    try {
      // 1. Get all pages for this PDF
      const pages = await step.runQuery(
        api.pdf.queries.getPdfPages,
        { pdfId },
        { name: `GetPDFPages-${pdfId}` }
      );
      
      if (!pages || pages.length === 0) {
        throw new Error(`No pages found for PDF ${pdfId}`);
      }
      
      console.log(`Found ${pages.length} pages for PDF ${pdfId}`);
      
      // 2. Check if all pages have cleaned text for at least one source
      let allPagesComplete = false;
      let completeSource: "gemini" | "replicate" | null = null;
      
      // Try the preferred source first if specified
      if (preferredSource) {
        const allComplete = await step.runQuery(
          internal.concatenate.queries.areAllPagesComplete,
          { pdfId, source: preferredSource },
          { name: `CheckCompletion-${preferredSource}-${pdfId}` }
        );
        
        if (allComplete) {
          allPagesComplete = true;
          completeSource = preferredSource;
        }
      }
      
      // If preferred source isn't complete or wasn't specified, check both sources
      if (!allPagesComplete) {
        // Try Gemini first (if it wasn't already the preferred source)
        if (preferredSource !== "gemini") {
          const geminiComplete = await step.runQuery(
            internal.concatenate.queries.areAllPagesComplete,
            { pdfId, source: "gemini" },
            { name: `CheckCompletion-gemini-${pdfId}` }
          );
          
          if (geminiComplete) {
            allPagesComplete = true;
            completeSource = "gemini";
          }
        }
        
        // Try Replicate if Gemini isn't complete
        if (!allPagesComplete && preferredSource !== "replicate") {
          const replicateComplete = await step.runQuery(
            internal.concatenate.queries.areAllPagesComplete,
            { pdfId, source: "replicate" },
            { name: `CheckCompletion-replicate-${pdfId}` }
          );
          
          if (replicateComplete) {
            allPagesComplete = true;
            completeSource = "replicate";
          }
        }
      }
      
      // If no source is fully complete, schedule another check after a delay
      if (!allPagesComplete || !completeSource) {
        console.log(`Not all pages complete for PDF ${pdfId}, will retry later (attempt ${retryCount})`);
        
        // Limit retry attempts to avoid infinite loops
        if (retryCount < 10) {
          // Schedule this same workflow to run again after 30 seconds
          // Instead of using sleep, we use the scheduler to run the workflow again
          await step.runAction(
            internal.concatenate.actions.recheckConcatenation,
            { 
              pdfId, 
              preferredSource,
              retryCount: retryCount + 1 
            },
            { 
              runAfter: 30000, // 30 seconds
              name: `RetryConcatenate-${pdfId}-${retryCount}` 
            }
          );
        } else {
          console.log(`Max retries reached for PDF ${pdfId}, giving up`);
        }
        
        return;
      }
      
      console.log(`All pages complete for PDF ${pdfId} using ${completeSource} source`);
      
      // 3. Concatenate the text for all pages in order
      const concatenatedText = await step.runQuery(
        internal.concatenate.queries.getConcatenatedText,
        { pdfId, source: completeSource },
        { name: `ConcatenateText-${pdfId}` }
      );
      
      // 4. Store the concatenated text
      await step.runMutation(
        internal.concatenate.mutations.saveConcatenatedText,
        { pdfId, source: completeSource, text: concatenatedText },
        { name: `SaveConcatenated-${pdfId}` }
      );
      
      // 5. Start the embedding process
      await step.runAction(
        api.ingest.ingest.chunkAndEmbed,
        { pdfId },
        { 
          retry: { maxAttempts: 3, initialBackoffMs: 1000, base: 2 },
          name: `ChunkAndEmbed-${pdfId}` 
        }
      );
      
      console.log(`Successfully processed PDF ${pdfId} with ${completeSource} source`);
    } catch (error) {
      console.error(`Error in concatenateAndEmbedWorkflow for PDF ${pdfId}:`, error);
      throw error;
    }
  },
});

export const startConcatenateWorkflow = internalMutation({
  args: {
    pdfId: v.id("pdfs"),
    preferredSource: v.optional(v.union(v.literal("gemini"), v.literal("replicate"))),
  },
  handler: async (ctx, args) => {
    await workflow.start(
      ctx,
      internal.workflow.concatenateWorkflow.concatenateAndEmbedWorkflow,
      { ...args, retryCount: 0 },
    );
  },
});


// File Path: convex/workflow/index.ts

// convex/workflows/index.ts
import { WorkflowManager } from "@convex-dev/workflow";
import { components } from "../_generated/api";

export const workflow = new WorkflowManager(components.workflow);


// File Path: convex/workflow/ocrWorkflow.ts

// convex/workflows/ocrWorkflow.ts
import { workflow } from "./index";
import { v } from "convex/values";
import { internal } from "../_generated/api";
import { Id } from "../_generated/dataModel";



export const ocrWorkflow = workflow.define({
  args: { pdfId: v.id("pdfs") },

  handler: async (
    step,
    { pdfId }
  ): Promise<{ pageIds: Id<"pages">[] }> => {
    // Split first
    const pageIds: Id<"pages">[] = await step.runAction(
      internal.pdf.actions.splitPdfIntoPages,
      { pdfId },
      { name: `SplitPDF-${pdfId}` }
    );

    // Spawn 2 · N child workflows and DON'T await anything
    for (const pageId of pageIds) {
      // Start the Gemini workflow
      await step.runMutation(
        internal.workflow.providerWorkflow.kickoffproviderWorkflow,
        { pageId, provider: "gemini" },
        { name: `GeminiWF-${pageId}` }
      );

      await step.runMutation(
        internal.workflow.providerWorkflow.kickoffproviderWorkflow,
        { pageId, provider: "replicate" },
        { name: `ReplicateWF-${pageId}` }
      );
      
    }

    await step.runMutation(
      internal.workflow.concatenateWorkflow.startConcatenateWorkflow,
      { pdfId },
      { name: `StartConcatenate-${pdfId}` }
    );

    // Return immediately — parent is done.
    return { pageIds };
  },
});




// File Path: convex/workflow/providerWorkflow.ts

// convex/workflows/providerWorkflow.ts
import { workflow } from "./index";
import { v } from "convex/values";
import { internal } from "../_generated/api";
import { internalMutation } from "../_generated/server";

export const providerWorkflow = workflow.define({
  args: {
    pageId: v.id("pages"),
    provider: v.union(v.literal("gemini"), v.literal("replicate")),
  },

  handler: async (step, { pageId, provider }): Promise<void> => {
    // 1. OCR with the chosen provider
    if (provider === "gemini") {
      await step.runAction(
        internal.ocr.gemini.actions.processPageWithOcr,
        { pageId },
        { 
            retry: { maxAttempts: 3, initialBackoffMs: 1000, base: 2 },
            name: `GeminiOCR-Page-${pageId}` 
          }
      );
    } else {
      await step.runAction(
        internal.ocr.replicate.actions.processPageWithOcr,
        { pageId },
        { 
            retry: { maxAttempts: 3, initialBackoffMs: 1000, base: 2 },
            name: `ReplicateOCR-Page-${pageId}` 
          }
      );
    }

    // 2. Clean the OCR results using the HTTP endpoint
    await step.runAction(
        internal.ocr.openai.actions.cleanPage,
        { pageId, source: provider },
        {
          retry: { maxAttempts: 3, initialBackoffMs: 2000, base: 2 },
          name: `CleanPageHTTP-${provider}-${pageId}`
        }
      );
    },
  });



export const kickoffproviderWorkflow = internalMutation({
    args: {
        pageId: v.id("pages"),
        provider: v.union(v.literal("gemini"), v.literal("replicate")),
    },
    handler: async (ctx, {pageId, provider}) => {
      await workflow.start(
        ctx,
        internal.workflow.providerWorkflow.providerWorkflow,
        { pageId, provider },
      );
    },
  });


// File Path: convex/workflow/startWorkflow.ts

import { v } from "convex/values";
import { workflow } from "./index";
import { internal } from "../_generated/api";
import { Id } from "../_generated/dataModel";


const s = internal.pdf.actions;


// This is a workflow definition, not a mutation
export const ocrWorkflow = workflow.define({
  args: {
    pdfId: v.id("pdfs"),
  },
  handler: async (step, { pdfId }): Promise<{ success: boolean; pageIds: Id<"pages">[] }> => {
    try {
      // 1. Split the PDF into pages
      const pageIds: Id<"pages">[] = await step.runAction(
        s.splitPdfIntoPages,
        { pdfId }
      );
      
      // Rest of workflow implementation...
      
      return { success: true, pageIds };
    } catch (error) {
      console.error(`Error in OCRWorkflow for PDF ${pdfId}:`, error);
      throw error;
    }
  },
});


// File Path: convex/workflowOrch.ts

import { mutation } from "./_generated/server";

import { v } from "convex/values";
import { api, internal } from "./_generated/api";
import {  internalAction } from "./_generated/server";

export const workflowOrch = internalAction({
    args: {
        pdfId: v.id("pdfs"),
    },
    handler: async (ctx, args) => {
        
await Promise.allSettled([     
 ctx.scheduler.runAfter(0, api.ocr.gemini.actions.processPdfWithOcr, { pdfId: args.pdfId }),
 ctx.scheduler.runAfter(0, api.ocr.replicate.actions.processPdfWithOcr, { pdfId: args.pdfId })
])
  

  
    }
});


export const workflowOrchMutation = mutation({
    args: {
        pdfId: v.id("pdfs"),
    },
    handler: async (ctx, args) => {
        await ctx.scheduler.runAfter(0, internal.workflowOrch.workflowOrch, {pdfId: args.pdfId})
    }
})



// File Path: convex/_generated/api.d.ts

/* eslint-disable */
/**
 * Generated `api` utility.
 *
 * THIS CODE IS AUTOMATICALLY GENERATED.
 *
 * To regenerate, run `npx convex dev`.
 * @module
 */

import type * as api_ from "../api.js";
import type * as concatenate_actions from "../concatenate/actions.js";
import type * as concatenate_mutations from "../concatenate/mutations.js";
import type * as concatenate_queries from "../concatenate/queries.js";
import type * as config from "../config.js";
import type * as files_mutations from "../files/mutations.js";
import type * as files_queries from "../files/queries.js";
import type * as http from "../http.js";
import type * as ingest_ingest from "../ingest/ingest.js";
import type * as ocr_gemini_actions from "../ocr/gemini/actions.js";
import type * as ocr_gemini_mutations from "../ocr/gemini/mutations.js";
import type * as ocr_gemini_queries from "../ocr/gemini/queries.js";
import type * as ocr_openai_actions from "../ocr/openai/actions.js";
import type * as ocr_openai_mutations from "../ocr/openai/mutations.js";
import type * as ocr_openai_queries from "../ocr/openai/queries.js";
import type * as ocr_replicate_actions from "../ocr/replicate/actions.js";
import type * as ocr_replicate_mutations from "../ocr/replicate/mutations.js";
import type * as ocr_replicate_queries from "../ocr/replicate/queries.js";
import type * as pdf_actions from "../pdf/actions.js";
import type * as pdf_mutations from "../pdf/mutations.js";
import type * as pdf_queries from "../pdf/queries.js";
import type * as performOCR from "../performOCR.js";
import type * as serve_serve from "../serve/serve.js";
import type * as utils_cleaner from "../utils/cleaner.js";
import type * as utils_geminiOcr from "../utils/geminiOcr.js";
import type * as utils_pdfSplitter from "../utils/pdfSplitter.js";
import type * as utils_retry from "../utils/retry.js";
import type * as utils_stream from "../utils/stream.js";
import type * as workflow_concatenateWorkflow from "../workflow/concatenateWorkflow.js";
import type * as workflow_index from "../workflow/index.js";
import type * as workflow_ocrWorkflow from "../workflow/ocrWorkflow.js";
import type * as workflow_providerWorkflow from "../workflow/providerWorkflow.js";
import type * as workflow_startWorkflow from "../workflow/startWorkflow.js";
import type * as workflowOrch from "../workflowOrch.js";

import type {
  ApiFromModules,
  FilterApi,
  FunctionReference,
} from "convex/server";

/**
 * A utility for referencing Convex functions in your app's API.
 *
 * Usage:
 * ```js
 * const myFunctionReference = api.myModule.myFunction;
 * ```
 */
declare const fullApi: ApiFromModules<{
  api: typeof api_;
  "concatenate/actions": typeof concatenate_actions;
  "concatenate/mutations": typeof concatenate_mutations;
  "concatenate/queries": typeof concatenate_queries;
  config: typeof config;
  "files/mutations": typeof files_mutations;
  "files/queries": typeof files_queries;
  http: typeof http;
  "ingest/ingest": typeof ingest_ingest;
  "ocr/gemini/actions": typeof ocr_gemini_actions;
  "ocr/gemini/mutations": typeof ocr_gemini_mutations;
  "ocr/gemini/queries": typeof ocr_gemini_queries;
  "ocr/openai/actions": typeof ocr_openai_actions;
  "ocr/openai/mutations": typeof ocr_openai_mutations;
  "ocr/openai/queries": typeof ocr_openai_queries;
  "ocr/replicate/actions": typeof ocr_replicate_actions;
  "ocr/replicate/mutations": typeof ocr_replicate_mutations;
  "ocr/replicate/queries": typeof ocr_replicate_queries;
  "pdf/actions": typeof pdf_actions;
  "pdf/mutations": typeof pdf_mutations;
  "pdf/queries": typeof pdf_queries;
  performOCR: typeof performOCR;
  "serve/serve": typeof serve_serve;
  "utils/cleaner": typeof utils_cleaner;
  "utils/geminiOcr": typeof utils_geminiOcr;
  "utils/pdfSplitter": typeof utils_pdfSplitter;
  "utils/retry": typeof utils_retry;
  "utils/stream": typeof utils_stream;
  "workflow/concatenateWorkflow": typeof workflow_concatenateWorkflow;
  "workflow/index": typeof workflow_index;
  "workflow/ocrWorkflow": typeof workflow_ocrWorkflow;
  "workflow/providerWorkflow": typeof workflow_providerWorkflow;
  "workflow/startWorkflow": typeof workflow_startWorkflow;
  workflowOrch: typeof workflowOrch;
}>;
declare const fullApiWithMounts: typeof fullApi;

export declare const api: FilterApi<
  typeof fullApiWithMounts,
  FunctionReference<any, "public">
>;
export declare const internal: FilterApi<
  typeof fullApiWithMounts,
  FunctionReference<any, "internal">
>;

export declare const components: {
  workflow: {
    journal: {
      load: FunctionReference<
        "query",
        "internal",
        { workflowId: string },
        {
          inProgress: Array<{
            _creationTime: number;
            _id: string;
            step: {
              args: any;
              argsSize: number;
              completedAt?: number;
              functionType: "query" | "mutation" | "action";
              handle: string;
              inProgress: boolean;
              name: string;
              runResult?:
                | { kind: "success"; returnValue: any }
                | { error: string; kind: "failed" }
                | { kind: "canceled" };
              startedAt: number;
              workId?: string;
            };
            stepNumber: number;
            workflowId: string;
          }>;
          journalEntries: Array<{
            _creationTime: number;
            _id: string;
            step: {
              args: any;
              argsSize: number;
              completedAt?: number;
              functionType: "query" | "mutation" | "action";
              handle: string;
              inProgress: boolean;
              name: string;
              runResult?:
                | { kind: "success"; returnValue: any }
                | { error: string; kind: "failed" }
                | { kind: "canceled" };
              startedAt: number;
              workId?: string;
            };
            stepNumber: number;
            workflowId: string;
          }>;
          logLevel: "DEBUG" | "TRACE" | "INFO" | "REPORT" | "WARN" | "ERROR";
          ok: boolean;
          workflow: {
            _creationTime: number;
            _id: string;
            args: any;
            generationNumber: number;
            logLevel?: any;
            name?: string;
            onComplete?: { context?: any; fnHandle: string };
            runResult?:
              | { kind: "success"; returnValue: any }
              | { error: string; kind: "failed" }
              | { kind: "canceled" };
            startedAt?: any;
            state?: any;
            workflowHandle: string;
          };
        }
      >;
      startStep: FunctionReference<
        "mutation",
        "internal",
        {
          generationNumber: number;
          name: string;
          retry?:
            | boolean
            | { base: number; initialBackoffMs: number; maxAttempts: number };
          schedulerOptions?: { runAt?: number } | { runAfter?: number };
          step: {
            args: any;
            argsSize: number;
            completedAt?: number;
            functionType: "query" | "mutation" | "action";
            handle: string;
            inProgress: boolean;
            name: string;
            runResult?:
              | { kind: "success"; returnValue: any }
              | { error: string; kind: "failed" }
              | { kind: "canceled" };
            startedAt: number;
            workId?: string;
          };
          workflowId: string;
          workpoolOptions?: {
            defaultRetryBehavior?: {
              base: number;
              initialBackoffMs: number;
              maxAttempts: number;
            };
            logLevel?: "DEBUG" | "TRACE" | "INFO" | "REPORT" | "WARN" | "ERROR";
            maxParallelism?: number;
            retryActionsByDefault?: boolean;
          };
        },
        {
          _creationTime: number;
          _id: string;
          step: {
            args: any;
            argsSize: number;
            completedAt?: number;
            functionType: "query" | "mutation" | "action";
            handle: string;
            inProgress: boolean;
            name: string;
            runResult?:
              | { kind: "success"; returnValue: any }
              | { error: string; kind: "failed" }
              | { kind: "canceled" };
            startedAt: number;
            workId?: string;
          };
          stepNumber: number;
          workflowId: string;
        }
      >;
    };
    workflow: {
      cancel: FunctionReference<
        "mutation",
        "internal",
        { workflowId: string },
        null
      >;
      cleanup: FunctionReference<
        "mutation",
        "internal",
        { workflowId: string },
        boolean
      >;
      complete: FunctionReference<
        "mutation",
        "internal",
        {
          generationNumber: number;
          now: number;
          runResult:
            | { kind: "success"; returnValue: any }
            | { error: string; kind: "failed" }
            | { kind: "canceled" };
          workflowId: string;
        },
        null
      >;
      create: FunctionReference<
        "mutation",
        "internal",
        {
          maxParallelism?: number;
          onComplete?: { context?: any; fnHandle: string };
          validateAsync?: boolean;
          workflowArgs: any;
          workflowHandle: string;
          workflowName: string;
        },
        string
      >;
      getStatus: FunctionReference<
        "query",
        "internal",
        { workflowId: string },
        {
          inProgress: Array<{
            _creationTime: number;
            _id: string;
            step: {
              args: any;
              argsSize: number;
              completedAt?: number;
              functionType: "query" | "mutation" | "action";
              handle: string;
              inProgress: boolean;
              name: string;
              runResult?:
                | { kind: "success"; returnValue: any }
                | { error: string; kind: "failed" }
                | { kind: "canceled" };
              startedAt: number;
              workId?: string;
            };
            stepNumber: number;
            workflowId: string;
          }>;
          logLevel: "DEBUG" | "TRACE" | "INFO" | "REPORT" | "WARN" | "ERROR";
          workflow: {
            _creationTime: number;
            _id: string;
            args: any;
            generationNumber: number;
            logLevel?: any;
            name?: string;
            onComplete?: { context?: any; fnHandle: string };
            runResult?:
              | { kind: "success"; returnValue: any }
              | { error: string; kind: "failed" }
              | { kind: "canceled" };
            startedAt?: any;
            state?: any;
            workflowHandle: string;
          };
        }
      >;
    };
  };
};



// File Path: convex/_generated/api.js

/* eslint-disable */
/**
 * Generated `api` utility.
 *
 * THIS CODE IS AUTOMATICALLY GENERATED.
 *
 * To regenerate, run `npx convex dev`.
 * @module
 */

import { anyApi, componentsGeneric } from "convex/server";

/**
 * A utility for referencing Convex functions in your app's API.
 *
 * Usage:
 * ```js
 * const myFunctionReference = api.myModule.myFunction;
 * ```
 */
export const api = anyApi;
export const internal = anyApi;
export const components = componentsGeneric();



// File Path: convex/_generated/dataModel.d.ts

/* eslint-disable */
/**
 * Generated data model types.
 *
 * THIS CODE IS AUTOMATICALLY GENERATED.
 *
 * To regenerate, run `npx convex dev`.
 * @module
 */

import type {
  DataModelFromSchemaDefinition,
  DocumentByName,
  TableNamesInDataModel,
  SystemTableNames,
} from "convex/server";
import type { GenericId } from "convex/values";
import schema from "../schema.js";

/**
 * The names of all of your Convex tables.
 */
export type TableNames = TableNamesInDataModel<DataModel>;

/**
 * The type of a document stored in Convex.
 *
 * @typeParam TableName - A string literal type of the table name (like "users").
 */
export type Doc<TableName extends TableNames> = DocumentByName<
  DataModel,
  TableName
>;

/**
 * An identifier for a document in Convex.
 *
 * Convex documents are uniquely identified by their `Id`, which is accessible
 * on the `_id` field. To learn more, see [Document IDs](https://docs.convex.dev/using/document-ids).
 *
 * Documents can be loaded using `db.get(id)` in query and mutation functions.
 *
 * IDs are just strings at runtime, but this type can be used to distinguish them from other
 * strings when type checking.
 *
 * @typeParam TableName - A string literal type of the table name (like "users").
 */
export type Id<TableName extends TableNames | SystemTableNames> =
  GenericId<TableName>;

/**
 * A type describing your Convex data model.
 *
 * This type includes information about what tables you have, the type of
 * documents stored in those tables, and the indexes defined on them.
 *
 * This type is used to parameterize methods like `queryGeneric` and
 * `mutationGeneric` to make them type-safe.
 */
export type DataModel = DataModelFromSchemaDefinition<typeof schema>;



// File Path: convex/_generated/server.d.ts

/* eslint-disable */
/**
 * Generated utilities for implementing server-side Convex query and mutation functions.
 *
 * THIS CODE IS AUTOMATICALLY GENERATED.
 *
 * To regenerate, run `npx convex dev`.
 * @module
 */

import {
  ActionBuilder,
  AnyComponents,
  HttpActionBuilder,
  MutationBuilder,
  QueryBuilder,
  GenericActionCtx,
  GenericMutationCtx,
  GenericQueryCtx,
  GenericDatabaseReader,
  GenericDatabaseWriter,
  FunctionReference,
} from "convex/server";
import type { DataModel } from "./dataModel.js";

type GenericCtx =
  | GenericActionCtx<DataModel>
  | GenericMutationCtx<DataModel>
  | GenericQueryCtx<DataModel>;

/**
 * Define a query in this Convex app's public API.
 *
 * This function will be allowed to read your Convex database and will be accessible from the client.
 *
 * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
 * @returns The wrapped query. Include this as an `export` to name it and make it accessible.
 */
export declare const query: QueryBuilder<DataModel, "public">;

/**
 * Define a query that is only accessible from other Convex functions (but not from the client).
 *
 * This function will be allowed to read from your Convex database. It will not be accessible from the client.
 *
 * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
 * @returns The wrapped query. Include this as an `export` to name it and make it accessible.
 */
export declare const internalQuery: QueryBuilder<DataModel, "internal">;

/**
 * Define a mutation in this Convex app's public API.
 *
 * This function will be allowed to modify your Convex database and will be accessible from the client.
 *
 * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
 * @returns The wrapped mutation. Include this as an `export` to name it and make it accessible.
 */
export declare const mutation: MutationBuilder<DataModel, "public">;

/**
 * Define a mutation that is only accessible from other Convex functions (but not from the client).
 *
 * This function will be allowed to modify your Convex database. It will not be accessible from the client.
 *
 * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
 * @returns The wrapped mutation. Include this as an `export` to name it and make it accessible.
 */
export declare const internalMutation: MutationBuilder<DataModel, "internal">;

/**
 * Define an action in this Convex app's public API.
 *
 * An action is a function which can execute any JavaScript code, including non-deterministic
 * code and code with side-effects, like calling third-party services.
 * They can be run in Convex's JavaScript environment or in Node.js using the "use node" directive.
 * They can interact with the database indirectly by calling queries and mutations using the {@link ActionCtx}.
 *
 * @param func - The action. It receives an {@link ActionCtx} as its first argument.
 * @returns The wrapped action. Include this as an `export` to name it and make it accessible.
 */
export declare const action: ActionBuilder<DataModel, "public">;

/**
 * Define an action that is only accessible from other Convex functions (but not from the client).
 *
 * @param func - The function. It receives an {@link ActionCtx} as its first argument.
 * @returns The wrapped function. Include this as an `export` to name it and make it accessible.
 */
export declare const internalAction: ActionBuilder<DataModel, "internal">;

/**
 * Define an HTTP action.
 *
 * This function will be used to respond to HTTP requests received by a Convex
 * deployment if the requests matches the path and method where this action
 * is routed. Be sure to route your action in `convex/http.js`.
 *
 * @param func - The function. It receives an {@link ActionCtx} as its first argument.
 * @returns The wrapped function. Import this function from `convex/http.js` and route it to hook it up.
 */
export declare const httpAction: HttpActionBuilder;

/**
 * A set of services for use within Convex query functions.
 *
 * The query context is passed as the first argument to any Convex query
 * function run on the server.
 *
 * This differs from the {@link MutationCtx} because all of the services are
 * read-only.
 */
export type QueryCtx = GenericQueryCtx<DataModel>;

/**
 * A set of services for use within Convex mutation functions.
 *
 * The mutation context is passed as the first argument to any Convex mutation
 * function run on the server.
 */
export type MutationCtx = GenericMutationCtx<DataModel>;

/**
 * A set of services for use within Convex action functions.
 *
 * The action context is passed as the first argument to any Convex action
 * function run on the server.
 */
export type ActionCtx = GenericActionCtx<DataModel>;

/**
 * An interface to read from the database within Convex query functions.
 *
 * The two entry points are {@link DatabaseReader.get}, which fetches a single
 * document by its {@link Id}, or {@link DatabaseReader.query}, which starts
 * building a query.
 */
export type DatabaseReader = GenericDatabaseReader<DataModel>;

/**
 * An interface to read from and write to the database within Convex mutation
 * functions.
 *
 * Convex guarantees that all writes within a single mutation are
 * executed atomically, so you never have to worry about partial writes leaving
 * your data in an inconsistent state. See [the Convex Guide](https://docs.convex.dev/understanding/convex-fundamentals/functions#atomicity-and-optimistic-concurrency-control)
 * for the guarantees Convex provides your functions.
 */
export type DatabaseWriter = GenericDatabaseWriter<DataModel>;



// File Path: convex/_generated/server.js

/* eslint-disable */
/**
 * Generated utilities for implementing server-side Convex query and mutation functions.
 *
 * THIS CODE IS AUTOMATICALLY GENERATED.
 *
 * To regenerate, run `npx convex dev`.
 * @module
 */

import {
  actionGeneric,
  httpActionGeneric,
  queryGeneric,
  mutationGeneric,
  internalActionGeneric,
  internalMutationGeneric,
  internalQueryGeneric,
  componentsGeneric,
} from "convex/server";

/**
 * Define a query in this Convex app's public API.
 *
 * This function will be allowed to read your Convex database and will be accessible from the client.
 *
 * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
 * @returns The wrapped query. Include this as an `export` to name it and make it accessible.
 */
export const query = queryGeneric;

/**
 * Define a query that is only accessible from other Convex functions (but not from the client).
 *
 * This function will be allowed to read from your Convex database. It will not be accessible from the client.
 *
 * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
 * @returns The wrapped query. Include this as an `export` to name it and make it accessible.
 */
export const internalQuery = internalQueryGeneric;

/**
 * Define a mutation in this Convex app's public API.
 *
 * This function will be allowed to modify your Convex database and will be accessible from the client.
 *
 * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
 * @returns The wrapped mutation. Include this as an `export` to name it and make it accessible.
 */
export const mutation = mutationGeneric;

/**
 * Define a mutation that is only accessible from other Convex functions (but not from the client).
 *
 * This function will be allowed to modify your Convex database. It will not be accessible from the client.
 *
 * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
 * @returns The wrapped mutation. Include this as an `export` to name it and make it accessible.
 */
export const internalMutation = internalMutationGeneric;

/**
 * Define an action in this Convex app's public API.
 *
 * An action is a function which can execute any JavaScript code, including non-deterministic
 * code and code with side-effects, like calling third-party services.
 * They can be run in Convex's JavaScript environment or in Node.js using the "use node" directive.
 * They can interact with the database indirectly by calling queries and mutations using the {@link ActionCtx}.
 *
 * @param func - The action. It receives an {@link ActionCtx} as its first argument.
 * @returns The wrapped action. Include this as an `export` to name it and make it accessible.
 */
export const action = actionGeneric;

/**
 * Define an action that is only accessible from other Convex functions (but not from the client).
 *
 * @param func - The function. It receives an {@link ActionCtx} as its first argument.
 * @returns The wrapped function. Include this as an `export` to name it and make it accessible.
 */
export const internalAction = internalActionGeneric;

/**
 * Define a Convex HTTP action.
 *
 * @param func - The function. It receives an {@link ActionCtx} as its first argument, and a `Request` object
 * as its second.
 * @returns The wrapped endpoint function. Route a URL path to this function in `convex/http.js`.
 */
export const httpAction = httpActionGeneric;



// File Path: next-env.d.ts

/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/app/api-reference/config/typescript for more information.



// File Path: next.config.ts

/** @type {import('next').NextConfig} */
const nextConfig = {
  experimental: {
    useLightningcss: false,  // ← turn off the Rust-based pipeline
  },
};

module.exports = nextConfig;



// File Path: package.json

{
  "name": "documents",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@ai-sdk/openai": "^1.3.20",
    "@convex-dev/workflow": "^0.2.3",
    "@google/genai": "^0.8.0",
    "@google/generative-ai": "^0.24.0",
    "@langchain/core": "^0.3.45",
    "@mdxeditor/editor": "^3.30.0",
    "@radix-ui/react-accordion": "^1.2.10",
    "@radix-ui/react-alert-dialog": "^1.1.11",
    "@radix-ui/react-slot": "^1.2.2",
    "@radix-ui/react-toggle": "^1.1.6",
    "@radix-ui/react-tooltip": "^1.2.6",
    "@tailwindcss/typography": "^0.5.16",
    "@types/lodash.debounce": "^4.0.9",
    "ai": "^4.3.10",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "convex": "^1.23.0",
    "langchain": "^0.3.22",
    "lightningcss-win32-x64-msvc": "^1.29.3",
    "lodash.debounce": "^4.0.8",
    "lucide": "^0.488.0",
    "lucide-react": "^0.488.0",
    "modern-async": "^2.0.4",
    "motion": "^12.9.4",
    "next": "15.2.5",
    "openai": "^4.94.0",
    "pdf-lib": "^1.17.1",
    "pdfjs-dist": "^3.11.174",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-dropzone": "^14.3.8",
    "react-markdown": "^10.1.0",
    "react-pdf": "^9.2.1",
    "replicate": "^1.0.1",
    "tailwind-merge": "^3.2.0",
    "tailwindcss": "^3.3.3",
    "zustand": "^5.0.4"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@tailwindcss/postcss": "^4.1.5",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "autoprefixer": "^10.4.21",
    "eslint": "^9",
    "eslint-config-next": "15.2.5",
    "postcss": "^8.5.3",
    "tw-animate-css": "^1.2.8",
    "typescript": "^5"
  }
}



// File Path: project-structure.txt

[dir]  .next/
[dir]  .next/cache/
[dir]  .next/cache/images/
[dir]  .next/cache/images/khLohs3sU48fkkOJb_AvcN8eWmQoTkPIgFLYyXIhkZM/
[dir]  .next/cache/images/lkGTckl_N0rZoyS3H7X0-JsbjylLjH72iuON0K_PVpk/
[dir]  .next/cache/images/MbtBF8NAd-kiJxVMwp9ZDgH3woFCaIb4HxhXot24Uz4/
[dir]  .next/cache/images/QFnq_OyjVY1lWN_xIqvolLj0Q6P2SkaVZP9z_e-2ze4/
[dir]  .next/cache/images/qQv0Z5n05_y7x4Nkcvp12IqyGuizoM8JT85YvsVHYVA/
[dir]  .next/cache/swc/
[dir]  .next/cache/swc/plugins/
[dir]  .next/cache/swc/plugins/v7_windows_x86_64_8.0.0/
[dir]  .next/cache/webpack/
[dir]  .next/cache/webpack/client-development/
[dir]  .next/cache/webpack/client-development-fallback/
[dir]  .next/cache/webpack/server-development/
[dir]  .next/server/
[dir]  .next/server/app/
[dir]  .next/server/app/_not-found/
[dir]  .next/server/app/chat/
[dir]  .next/server/app/pdf/
[dir]  .next/server/app/pdf/[storageId]/
[dir]  .next/server/app/pdf/[storageId]/pages/
[dir]  .next/server/vendor-chunks/
[dir]  .next/static/
[dir]  .next/static/chunks/
[dir]  .next/static/chunks/app/
[dir]  .next/static/chunks/app/_not-found/
[dir]  .next/static/chunks/app/chat/
[dir]  .next/static/chunks/app/pdf/
[dir]  .next/static/chunks/app/pdf/[storageId]/
[dir]  .next/static/chunks/app/pdf/[storageId]/pages/
[dir]  .next/static/css/
[dir]  .next/static/css/app/
[dir]  .next/static/development/
[dir]  .next/static/media/
[dir]  .next/static/webpack/
[dir]  .next/static/webpack/app/
[dir]  .next/static/webpack/app/chat/
[dir]  .next/static/webpack/app/pdf/
[dir]  .next/static/webpack/app/pdf/[storageId]/
[dir]  .next/static/webpack/app/pdf/[storageId]/pages/
[dir]  .next/types/
[dir]  .next/types/app/
[dir]  .next/types/app/chat/
[dir]  .next/types/app/pdf/
[dir]  .next/types/app/pdf/[storageId]/
[dir]  .next/types/app/pdf/[storageId]/pages/
[dir]  convex/
[dir]  convex/_generated/
[dir]  convex/concatenate/
[dir]  convex/files/
[dir]  convex/ingest/
[dir]  convex/ocr/
[dir]  convex/ocr/gemini/
[dir]  convex/ocr/openai/
[dir]  convex/ocr/replicate/
[dir]  convex/pdf/
[dir]  convex/serve/
[dir]  convex/utils/
[dir]  convex/workflow/
[dir]  public/
[dir]  src/
[dir]  src/app/
[dir]  src/app/chat/
[dir]  src/app/components/
[dir]  src/app/pdf/
[dir]  src/app/pdf/[storageId]/
[dir]  src/app/pdf/[storageId]/components/
[dir]  src/app/pdf/[storageId]/hooks/
[dir]  src/app/pdf/[storageId]/pages/
[dir]  src/app/pdf/[storageId]/types/
[dir]  src/app/pdf/[storageId]/utils/
[dir]  src/app/pdf/hooks/
[dir]  src/app/pdf/pages/
[dir]  src/components/
[dir]  src/components/ui/
[dir]  src/lib/
[dir]  src/services/
[dir]  src/store/
[dir]  src/utils/
[file] .env
[file] .env.local
[file] .gitignore
[file] components.json
[file] copy_content.sh
[file] eslint.config.mjs
[file] next-env.d.ts
[file] next.config.ts
[file] package-lock.json
[file] package.json
[file] postcss.config.mjs
[file] project_contents.txt
[file] project-structure.txt
[file] README.md
[file] tailwind.config.ts
[file] tsconfig.json
[file] tsconfig.tsbuildinfo 


// File Path: project_contents.txt




// File Path: README.md

This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.



// File Path: src/app/chat/layout.tsx

export default function ChatLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <div className="h-screen">
      {children}
    </div>
  );
} 


// File Path: src/app/chat/page.tsx

"use client";

import { useState, useEffect } from "react";
import { Button } from "@/components/ui/button";
import ChatInput from "../components/Chatnput";
import ChatMessages from "../components/ChatMessages";
import { Trash2 } from "lucide-react";
import Sources from "../components/Sources";
import PDFViewer from "../components/PDFViewer";
import ChatHeader from "../components/ChatHeader";
import { useRouter } from "next/navigation";

// Polyfill for crypto.randomUUID
const generateUUID = () => {
  try {
    return crypto.randomUUID();
  } catch {
    // Fallback implementation if randomUUID is not available
    return "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx".replace(
      /[xy]/g,
      function (c) {
        const r = (Math.random() * 16) | 0;
        const v = c === "x" ? r : (r & 0x3) | 0x8;
        return v.toString(16);
      }
    );
  }
};

export default function Chat() {
  const [input, setInput] = useState("");
  const [sessionId, setSessionId] = useState<string>("");
  const [pdfUrl, setPdfUrl] = useState<string>("");
  const router = useRouter();

  // Initialize sessionId after component mounts to avoid SSR issues
  useEffect(() => {
    setSessionId(generateUUID());
  }, []);

  const clearChat = () => {
    setSessionId(generateUUID());
    setPdfUrl("");
    router.refresh();
  };

  return (
    <div
      className="min-h-[calc(100vh-4rem)] md:h-full w-full"
      style={{
        backgroundImage: 'url("/background.png")',
        backgroundSize: "cover",
        backgroundPosition: "center",
        backgroundRepeat: "no-repeat",
        backgroundAttachment: "fixed",
      }}
    >
      <div className="flex flex-col md:flex-row h-auto md:h-full">
        <PDFViewer pdfUrl={pdfUrl} />
        <div className="w-full md:w-1/2 p-3 flex flex-col h-auto md:h-[95%]">
          <div className="bg-white/10 backdrop-blur-md shadow-lg rounded-2xl p-3 border border-white/20 flex-grow flex flex-col overflow-auto max-h-[80vh] md:max-h-none">
            <ChatHeader />
            <ChatMessages sessionId={sessionId} />
            <Sources sessionId={sessionId} setPdfUrl={setPdfUrl} />

            <div className="flex items-center gap-2 mb-1 justify-center">
              <div className="max-w-[600px] flex-1">
                <ChatInput
                  input={input}
                  setInput={setInput}
                  setMessages={() => {}}
                  sessionId={sessionId}
                />
              </div>
              <Button
                onClick={clearChat}
                variant="destructive"
                size="icon"
                className="bg-emerald-950 hover:bg-emerald-600"
                title="حذف المحادثه"
              >
                <Trash2 size={18} />
              </Button>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}



// File Path: src/app/components/Background.tsx

import React from 'react'

function Background() {
  return (
    <div 
      className="flex flex-col md:flex-row h-screen"
      style={{
        backgroundImage: 'url("/background.png")',
        backgroundSize: 'cover',
        backgroundPosition: 'center',
        backgroundRepeat: 'no-repeat'
      }}
    />
    
  )
}

export default Background


// File Path: src/app/components/ChatHeader.tsx

import React from 'react';

export default function ChatHeader() {
  return (
    <div className="mb-4 text-right">
      <h2 className="text-2xl font-semibold text-white">المحادثة</h2>
      <p className="text-white/70 text-sm">
          اطرح سؤالك وسأجد المستند المناسب
      </p>
    </div>
  );
}


// File Path: src/app/components/ChatMessage.tsx

"use client"

import React from 'react';
import ReactMarkdown from 'react-markdown';
import TypingIndicator from './TypingIndicator';

export default function ChatMessage({ message, isUser }: {message: string, isUser: boolean}) {
  return (
    <div className={`flex justify-${isUser ? "end" : "start"} mb-4`}>
      <div className={`max-w-[80%] rounded-2xl px-4 py-2 ${isUser?  "bg-emerald-600" : "bg-white/10 backdrop-blur-md border border-white/20"} text-white`}>
        {message === "" ? (
          <TypingIndicator/> 
        ) : (
          <div className={`prose prose-invert prose-sm max-w-none break-words ${isUser ? "" : "prose-headings:text-white prose-a:text-blue-300 text-right"}`}>
            <ReactMarkdown >
              {message}
            </ReactMarkdown>
          </div>
        )}
        <p className="text-xs mt-1 text-emerald-200 text-right">
          {new Date().toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit' })}
        </p>
      </div>
    </div>
  );
}


// File Path: src/app/components/ChatMessages.tsx

"use client"
import { useEffect, useRef } from 'react';
import ChatMessage from './ChatMessage';
import { useQuery } from 'convex/react';
import { api } from '../../../convex/_generated/api';

export default function ChatMessages({  sessionId }: {  sessionId: string }) {
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const retrieveMessages = useQuery(api.serve.serve.retrieveMessages, { sessionId: sessionId });

  const messages = retrieveMessages;
  
  // Scroll to bottom whenever messages change
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  return (
    <div className="flex-grow overflow-y-auto mb-4 space-y-4 scrollbar-thin scrollbar-thumb-white/20 scrollbar-track-transparent pr-2">
      {/* Welcome message */}
      <div className="flex justify-start">
        <div className="bg-white/20 text-white rounded-2xl px-4 py-2">
          <p className="text-right">مرحباً! كيف يمكنني مساعدتك؟ اطرح سؤالاً وسأساعدك في العثور على المعلومات المناسبة من المستندات المتاحة.</p>
        </div>
      </div>
      
      {/* Sample messages */}
      {messages && messages.map((message, index) => (
        <ChatMessage key={index} message={message.text} isUser={message.isUser} />
      ))}
      {/* <TypingIndicator /> */}
      
      {/* Invisible element for scroll reference */}
      <div ref={messagesEndRef} />
    </div>
  );
}


// File Path: src/app/components/Chatnput.tsx

"use client"
import { Send } from 'lucide-react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { api } from '../../../convex/_generated/api';
import { useMutation } from 'convex/react';
import { Id } from '../../../convex/_generated/dataModel';
import { ChangeEvent, KeyboardEvent } from 'react';

export default function ChatInput({ input, setInput, setMessages, sessionId }: 
  { 
    input: string, 
    setInput: (input: string) => void, 
    setMessages: React.Dispatch<React.SetStateAction<string[]>>, 
    sessionId: string 
  }) {

  const saveMessage = useMutation(api.serve.serve.saveMessage);

  const handleSendMessage = async (): Promise<void> => {
    if (input.trim() === '') return;
    
    // Add user message to the chat
    const userMessage = input;
    
    setMessages(prevMessages => [...prevMessages, userMessage]);
    await saveMessage({
      message: userMessage,
      sessionId: sessionId as Id<"chatSessions">,
      isUser: true,
    });
    
    setInput('');
  }
    
  const handleKeyDown = (e: KeyboardEvent<HTMLTextAreaElement>): void => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSendMessage();
    }
  };

  return (
    <div className="w-full relative">
      <Textarea
        placeholder="اكتب سؤالك هنا..."
        className="w-full bg-white/10 text-white placeholder-white/50 rounded-xl pl-12 pr-4 focus:outline-none focus:ring-2 focus:ring-emerald-500 min-h-[44px] py-2 resize-none"
        dir="rtl"
        value={input}
        onChange={(e: ChangeEvent<HTMLTextAreaElement>) => setInput(e.target.value)}
        onKeyDown={handleKeyDown}
        rows={3}
      />
      <div className="absolute left-3 inset-y-0 flex items-center">
        <Button variant="ghost"
          className="p-1.5 rounded-full bg-emerald-600 text-white h-8 w-8 flex items-center justify-center"
          onClick={handleSendMessage}
          disabled={input.trim() === ''}
        >
          <Send size={15} />
        </Button>
      </div>
    </div>
  );
}


// File Path: src/app/components/Navigation.tsx

import React from 'react';
import Image from 'next/image';
import Link from 'next/link';

const Navigation = () => {
  return (
    <nav className="fixed top-0 left-0 right-0 h-16 flex items-center justify-center border-b border-emerald-900 bg-emerald-950 backdrop-blur-sm z-10">
      <div className="max-w-screen-xl w-full mx-auto px-4 flex justify-center">
        <Link href="/" className="flex items-center">
          {/* Replace with your actual logo or use a placeholder */}
          <div className="relative w-40 h-10">
            <Image 
              src="/logo.svg" 
              alt="Logo"
              fill
              style={{ objectFit: 'contain' }}
              priority
            />
          </div>
        </Link>
      </div>
    </nav>
  );
};

export default Navigation; 


// File Path: src/app/components/PDFViewer.tsx

// src/app/components/PDFViewer.tsx
"use client";

import React, {
  useEffect,
  useRef,
  forwardRef,
  useImperativeHandle,
  useState,
} from "react";
import * as pdfjs from "pdfjs-dist";

// Set up PDF.js worker
pdfjs.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjs.version}/pdf.worker.min.js`;

interface PDFViewerProps {
  pdfUrl: string | null;
  initialPage?: number;
  onPageChange?: (page: number) => void;
  fitToWidth?: boolean;
  maxScale?: number;
}

export interface PDFViewerHandle {
  goToPage: (page: number) => void;
}

const PDFViewer = forwardRef<PDFViewerHandle, PDFViewerProps>(
  (
    {
      pdfUrl,
      initialPage = 1,
      onPageChange,
      fitToWidth = true,
      maxScale = 2.0,
    },
    ref
  ) => {
    const containerRef = useRef<HTMLDivElement>(null);
    const canvasContainerRef = useRef<HTMLDivElement>(null);
    const currentPageRef = useRef(initialPage);
    const pdfDocumentRef = useRef<pdfjs.PDFDocumentProxy | null>(null);
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState<string | null>(null);
    const [currentFitMode, setCurrentFitMode] = useState(fitToWidth);

    // Update fit mode when prop changes
    useEffect(() => {
      setCurrentFitMode(fitToWidth);
      if (pdfDocumentRef.current) {
        renderPage(currentPageRef.current);
      }
    }, [fitToWidth]);

    // Expose goToPage method via ref
    useImperativeHandle(ref, () => ({
      goToPage: (page: number) => {
        if (pdfDocumentRef.current) {
          renderPage(page);
        }
      },
    }));

    const calculateScale = (
      viewport: pdfjs.PageViewport,
      containerWidth: number,
      containerHeight: number
    ): number => {
      if (!currentFitMode) return 1.0;

      // Calculate scale to fit both width and height
      const widthScale = containerWidth / viewport.width;
      const heightScale = containerHeight / viewport.height;

      // Use the smaller scale to ensure the page fits in both dimensions
      const scale = Math.min(widthScale, heightScale);

      // Clamp the scale between 0.1 and maxScale
      return Math.min(Math.max(scale, 0.1), maxScale);
    };

    const renderPage = async (pageNumber: number) => {
      if (
        !pdfDocumentRef.current ||
        !containerRef.current ||
        !canvasContainerRef.current
      )
        return;

      try {
        setIsLoading(true);
        setError(null);

        const page = await pdfDocumentRef.current.getPage(pageNumber);
        const container = containerRef.current;
        const canvasContainer = canvasContainerRef.current;

        // Get the container dimensions
        const containerWidth = container.clientWidth - 40; // Account for padding
        const containerHeight = container.clientHeight - 40; // Account for padding

        // Get viewport with default scale first
        const viewport = page.getViewport({ scale: 1.0 });

        // Calculate appropriate scale to fit
        const scale = calculateScale(viewport, containerWidth, containerHeight);
        const scaledViewport = page.getViewport({ scale });

        // Create canvas
        const canvas = document.createElement("canvas");
        const context = canvas.getContext("2d")!;
        canvas.height = scaledViewport.height;
        canvas.width = scaledViewport.width;

        // Clear container and append canvas
        canvasContainer.innerHTML = "";
        canvasContainer.appendChild(canvas);

        // Center the canvas in the container
        canvas.style.display = "block";
        canvas.style.margin = "0 auto";

        // Render page
        await page.render({
          canvasContext: context,
          viewport: scaledViewport,
        }).promise;

        // Update current page and notify parent
        currentPageRef.current = pageNumber;
        onPageChange?.(pageNumber);
      } catch (error) {
        console.error("Error rendering page:", error);
        setError(
          `خطأ في عرض الصفحة: ${error instanceof Error ? error.message : String(error)}`
        );
      } finally {
        setIsLoading(false);
      }
    };

    useEffect(() => {
      if (!pdfUrl) return;

      let mounted = true;
      const loadPDF = async () => {
        try {
          setIsLoading(true);
          setError(null);

          const pdf = await pdfjs.getDocument(pdfUrl).promise;

          if (!mounted) {
            pdf.destroy();
            return;
          }

          pdfDocumentRef.current = pdf;
          // Render initial page
          await renderPage(initialPage);
        } catch (error) {
          console.error("Error loading PDF:", error);
          if (mounted) {
            setError(
              `خطأ في تحميل الملف: ${error instanceof Error ? error.message : String(error)}`
            );
          }
        } finally {
          if (mounted) {
            setIsLoading(false);
          }
        }
      };

      loadPDF();

      // Cleanup
      return () => {
        mounted = false;
        if (pdfDocumentRef.current) {
          pdfDocumentRef.current.destroy();
          pdfDocumentRef.current = null;
        }
      };
    }, [pdfUrl, initialPage]);

    // Handle window resize
    useEffect(() => {
      const handleResize = () => {
        if (pdfDocumentRef.current) {
          renderPage(currentPageRef.current);
        }
      };

      let timeoutId: NodeJS.Timeout;
      const debouncedResize = () => {
        clearTimeout(timeoutId);
        timeoutId = setTimeout(handleResize, 150);
      };

      window.addEventListener("resize", debouncedResize);
      return () => {
        window.removeEventListener("resize", debouncedResize);
        clearTimeout(timeoutId);
      };
    }, []);

    // Handle keyboard navigation
    useEffect(() => {
      const handleKeyDown = (e: KeyboardEvent) => {
        if (!pdfDocumentRef.current) return;

        const totalPages = pdfDocumentRef.current.numPages;

        if (e.key === "ArrowUp" || e.key === "ArrowLeft") {
          e.preventDefault();
          if (currentPageRef.current > 1) {
            renderPage(currentPageRef.current - 1);
          }
        } else if (e.key === "ArrowDown" || e.key === "ArrowRight") {
          e.preventDefault();
          if (currentPageRef.current < totalPages) {
            renderPage(currentPageRef.current + 1);
          }
        }
      };

      window.addEventListener("keydown", handleKeyDown);
      return () => window.removeEventListener("keydown", handleKeyDown);
    }, []);

    if (error) {
      return (
        <div className="flex items-center justify-center h-full text-red-400 bg-red-900/10 rounded-lg border border-red-500/20 p-4">
          <div className="text-center">
            <p className="text-sm">{error}</p>
            <button
              onClick={() => window.location.reload()}
              className="mt-2 text-xs text-red-400 hover:text-red-300 transition-colors"
            >
              إعادة المحاولة
            </button>
          </div>
        </div>
      );
    }

    return (
      <div
        ref={containerRef}
        className="relative w-full h-full overflow-hidden bg-white/10 rounded-lg p-4"
      >
        {isLoading && (
          <div className="absolute inset-0 flex items-center justify-center bg-emerald-950/80 backdrop-blur-sm rounded-lg z-10">
            <div className="flex items-center gap-3 text-white">
              <div className="animate-spin rounded-full h-6 w-6 border-b-2 border-emerald-400"></div>
              <span>جاري تحميل الملف...</span>
            </div>
          </div>
        )}

        <div
          ref={canvasContainerRef}
          className="w-full h-full flex items-center justify-center"
        />

        {pdfUrl && !isLoading && !error && (
          <div className="absolute bottom-2 left-2 bg-black/50 backdrop-blur-sm text-white text-xs px-2 py-1 rounded">
            صفحة {currentPageRef.current} من {pdfDocumentRef.current?.numPages}
          </div>
        )}
      </div>
    );
  }
);

PDFViewer.displayName = "PDFViewer";

export default PDFViewer;



// File Path: src/app/components/Sources.tsx

"use client"

import React, { useState, useEffect } from 'react';
import { useQuery } from 'convex/react';
import { api } from '../../../convex/_generated/api';
import { Id } from '../../../convex/_generated/dataModel';
import { Toggle } from "@/components/ui/toggle"

interface SourcesProps {
  sessionId: string;
  setPdfUrl: (url: string) => void;
}

export default function Sources({ sessionId, setPdfUrl }: SourcesProps) {
  // Fetch all ragSources entries for this session
  const sourcesData = useQuery(api.serve.serve.getRagSources, { sessionId });
  // Use the latest entry's pdfIds or empty array
  const pdfIds: Id<'pdfs'>[] = sourcesData?.[sourcesData.length - 1]?.pdfIds ?? [];

  // Track which PDF is selected
  const [selectedPdfId, setSelectedPdfId] = useState<Id<'pdfs'> | null>(null);

  // Query metadata and file URL when a PDF is selected
  const pdfMeta = useQuery(api.pdf.queries.getPdf, selectedPdfId ? { pdfId: selectedPdfId } : 'skip');
  const fileUrl = useQuery(
    api.files.queries.getFileDownloadUrl,
    pdfMeta?.fileId ? { fileId: pdfMeta.fileId } : 'skip'
  );

  // Whenever fileUrl changes, update the parent PDFViewer
  useEffect(() => {
    if (fileUrl) {
      setPdfUrl(fileUrl);
    }
  }, [fileUrl, setPdfUrl]);

  // If there are no sources yet, render nothing
  if (!pdfIds.length) {
    return null;
  }

  // Render toggle buttons for each PDF source
  return (
    <div className="mb-4 animate-in fade-in duration-300">
      <div className="flex flex-wrap gap-2">
        {pdfIds.map((id) => (
          <Toggle
            key={id.toString()}
            pressed={selectedPdfId === id}
            onPressedChange={() => setSelectedPdfId(id)}
            variant="outline"
            className="bg-emerald-950 border-emerald-700/90 text-white/50 h-8 w-20 p-5 rounded-3xl
              data-[state=on]:bg-emerald-600/50 data-[state=on]:text-white 
              transition-colors duration-200"
          >
            المصدر
          </Toggle>
        ))}
      </div>
    </div>
  );
} 


// File Path: src/app/components/TypingIndicator.tsx

import React from 'react';

export default function TypingIndicator() {
  return (
    <div className="flex justify-start">
      <div className="">
        <div className="flex space-x-2 rtl:space-x-reverse">
          <div className="w-2 h-2 rounded-full bg-white/60 animate-bounce" style={{ animationDelay: '0ms' }}></div>
          <div className="w-2 h-2 rounded-full bg-white/60 animate-bounce" style={{ animationDelay: '150ms' }}></div>
          <div className="w-2 h-2 rounded-full bg-white/60 animate-bounce" style={{ animationDelay: '300ms' }}></div>
        </div>
      </div>
    </div>
  );
}


// File Path: src/app/ConvexClientProvider.tsx

"use client";

import { ConvexProvider, ConvexReactClient } from "convex/react";
import { ReactNode } from "react";

const convex = new ConvexReactClient(process.env.NEXT_PUBLIC_CONVEX_URL!);

export function ConvexClientProvider({ children }: { children: ReactNode }) {
  return <ConvexProvider client={convex}>{children}</ConvexProvider>;
}


// File Path: src/app/globals.css

/* src/app/globals.css */
@tailwind base;
@tailwind components;
@tailwind utilities;

:root {
  --radius: 0.625rem;
  --background: oklch(1 0 0);
  --foreground: oklch(0.145 0 0);
  --card: oklch(1 0 0);
  --card-foreground: oklch(0.145 0 0);
  --popover: oklch(1 0 0);
  --popover-foreground: oklch(0.145 0 0);
  --primary: oklch(0.205 0 0);
  --primary-foreground: oklch(0.985 0 0);
  --secondary: oklch(0.97 0 0);
  --secondary-foreground: oklch(0.205 0 0);
  --muted: oklch(0.97 0 0);
  --muted-foreground: oklch(0.556 0 0);
  --accent: oklch(0.97 0 0);
  --accent-foreground: oklch(0.205 0 0);
  --destructive: oklch(0.577 0.245 27.325);
  --border: oklch(0.922 0 0);
  --input: oklch(0.922 0 0);
  --ring: oklch(0.708 0 0);
  --chart-1: oklch(0.646 0.222 41.116);
  --chart-2: oklch(0.6 0.118 184.704);
  --chart-3: oklch(0.398 0.07 227.392);
  --chart-4: oklch(0.828 0.189 84.429);
  --chart-5: oklch(0.769 0.188 70.08);
  --sidebar: oklch(0.985 0 0);
  --sidebar-foreground: oklch(0.145 0 0);
  --sidebar-primary: oklch(0.205 0 0);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.97 0 0);
  --sidebar-accent-foreground: oklch(0.205 0 0);
  --sidebar-border: oklch(0.922 0 0);
  --sidebar-ring: oklch(0.708 0 0);
}

.dark {
  --background: oklch(0.145 0 0);
  --foreground: oklch(0.985 0 0);
  --card: oklch(0.205 0 0);
  --card-foreground: oklch(0.985 0 0);
  --popover: oklch(0.205 0 0);
  --popover-foreground: oklch(0.985 0 0);
  --primary: oklch(0.922 0 0);
  --primary-foreground: oklch(0.205 0 0);
  --secondary: oklch(0.269 0 0);
  --secondary-foreground: oklch(0.985 0 0);
  --muted: oklch(0.269 0 0);
  --muted-foreground: oklch(0.708 0 0);
  --accent: oklch(0.269 0 0);
  --accent-foreground: oklch(0.985 0 0);
  --destructive: oklch(0.704 0.191 22.216);
  --border: oklch(1 0 0 / 10%);
  --input: oklch(1 0 0 / 15%);
  --ring: oklch(0.556 0 0);
  --chart-1: oklch(0.488 0.243 264.376);
  --chart-2: oklch(0.696 0.17 162.48);
  --chart-3: oklch(0.769 0.188 70.08);
  --chart-4: oklch(0.627 0.265 303.9);
  --chart-5: oklch(0.645 0.246 16.439);
  --sidebar: oklch(0.205 0 0);
  --sidebar-foreground: oklch(0.985 0 0);
  --sidebar-primary: oklch(0.488 0.243 264.376);
  --sidebar-primary-foreground: oklch(0.985 0 0);
  --sidebar-accent: oklch(0.269 0 0);
  --sidebar-accent-foreground: oklch(0.985 0 0);
  --sidebar-border: oklch(1 0 0 / 10%);
  --sidebar-ring: oklch(0.556 0 0);
}

html, body {
  height: 100%;
  margin: 0;
  padding: 0;
  overflow-x: hidden;
}

@layer base {
  * {
    @apply border-border;
    outline-color: var(--ring);
    outline-width: 2px;
    outline-offset: 2px;
  }
  body {
    @apply bg-background text-foreground;
    font-family: 'IBM Plex Sans Arabic', sans-serif;
  }
}

/* Custom Scrollbar Styles */
@layer utilities {
  /* Webkit browsers (Chrome, Safari, Edge) */
  .custom-scrollbar::-webkit-scrollbar {
    width: 8px;
    height: 8px;
  }

  .custom-scrollbar::-webkit-scrollbar-track {
    @apply bg-emerald-950/30 backdrop-blur-sm rounded-full;
  }

  .custom-scrollbar::-webkit-scrollbar-thumb {
    @apply bg-emerald-500/60 rounded-full transition-colors duration-200;
  }

  .custom-scrollbar::-webkit-scrollbar-thumb:hover {
    @apply bg-emerald-500/80;
  }

  .custom-scrollbar::-webkit-scrollbar-thumb:active {
    @apply bg-emerald-500;
  }

  /* Firefox */
  .custom-scrollbar {
    scrollbar-width: thin;
    scrollbar-color: rgb(16 185 129 / 0.6) rgb(6 78 59 / 0.3);
  }

  /* Thin scrollbar variant */
  .custom-scrollbar-thin::-webkit-scrollbar {
    width: 4px;
    height: 4px;
  }

  .custom-scrollbar-thin::-webkit-scrollbar-track {
    @apply bg-transparent;
  }

  .custom-scrollbar-thin::-webkit-scrollbar-thumb {
    @apply bg-emerald-500/40 rounded-full;
  }

  .custom-scrollbar-thin::-webkit-scrollbar-thumb:hover {
    @apply bg-emerald-500/60;
  }
}

/* Animation for QR code popup */
@keyframes slideInLeft {
  from {
    transform: translateX(-100%);
    opacity: 0;
  }
  to {
    transform: translateX(0);
    opacity: 1;
  }
}

@keyframes slideOutLeft {
  from {
    transform: translateX(0);
    opacity: 1;
  }
  to {
    transform: translateX(-100%);
    opacity: 0;
  }
}

.animate-slide-in-left {
  animation: slideInLeft 0.5s ease-out forwards;
}

.animate-slide-out-left {
  animation: slideOutLeft 0.5s ease-out forwards;
}


// File Path: src/app/layout.tsx

import type { Metadata } from "next";
import { IBM_Plex_Sans_Arabic, Geist_Mono } from "next/font/google";
import "./globals.css";
import { ConvexClientProvider } from "./ConvexClientProvider";
import Navigation from "./components/Navigation";

const ibmPlexSansArabic = IBM_Plex_Sans_Arabic({
  variable: "--font-ibm-plex-sans-arabic",
  subsets: ["arabic", "latin"],
  weight: ["100", "200", "300", "400", "500", "600", "700"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "تحويل المستندات إلى نصوص",
  description: "PDF OCR processing application",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="ar-en" className="h-full">
      <body
        className={`${ibmPlexSansArabic.variable} ${geistMono.variable} antialiased h-full`}
        style={{ fontFamily: `'IBM Plex Sans Arabic', sans-serif` }}
      >
        <ConvexClientProvider>
          <div className="h-full flex flex-col ">
            <Navigation />
            <main className="flex-1 pt-16 overflow-auto ">{children}</main>
          </div>
        </ConvexClientProvider>
      </body>
    </html>
  );
}



// File Path: src/app/page.tsx

"use client";

import { useState, useEffect } from "react";
import { useMutation } from "convex/react";
import { api } from "../../convex/_generated/api";
import { useRouter } from "next/navigation";
import PDFDropzone from "@/components/PDFDropzone";
import UploadButton from "@/components/UploadButton";
import { MessageCircleMore } from "lucide-react";
import { TextGenerateEffect } from "@/components/ui/text-generate-effect";
import QRCodePopup from "@/components/QRCodePopup";

// Define types for our mutation functions to avoid 'any'
type GenerateUploadUrlFn = () => Promise<string>;
type SendPDFFn = (args: {
  fileId: string;
  filename: string;
  fileSize: number;
  pageCount: number;
}) => Promise<string>;
type ProcessPDFFn = (args: { pdfId: string }) => Promise<void>;

const words = "الإدارة العامة للذكاء الإصطناعي وتطوير الأعمال";
function TextGenerateEffectDemo() {
  return <TextGenerateEffect words={words} />;
}

export default function App() {
  const router = useRouter();
  const generateUploadUrl = useMutation(api.files.mutations.generateUploadUrl);
  const sendPDF = useMutation(api.pdf.mutations.savePdfMetadata);
  // const processWithMultipleOcrMutation = useMutation(api.ocr.actions.processWithMultipleOcrMutation);
  const workflowOrchMutation = useMutation(
    api.workflowOrch.workflowOrchMutation
  );
  const [selectedPDF, setSelectedPDF] = useState<File | null>(null);
  const [pageCount, setPageCount] = useState<number | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [redirectUrl, setRedirectUrl] = useState<string | null>(null);
  const [showQRPopup, setShowQRPopup] = useState(true);

  // Handle redirection using useEffect
  useEffect(() => {
    if (redirectUrl) {
      router.push(redirectUrl);
    }
  }, [redirectUrl, router]);

  async function handleFormSubmit() {
    if (!selectedPDF) return;

    setIsLoading(true);
    try {
      // Generate upload URL and upload the PDF
      const postUrl = await (
        generateUploadUrl as unknown as GenerateUploadUrlFn
      )();

      // Upload the file to storage
      const result = await fetch(postUrl, {
        method: "POST",
        headers: { "Content-Type": selectedPDF.type },
        body: selectedPDF,
      });
      const { storageId } = await result.json();

      // Save PDF metadata
      const pdfId = await (sendPDF as unknown as SendPDFFn)({
        fileId: storageId,
        filename: selectedPDF.name,
        fileSize: selectedPDF.size,
        pageCount: pageCount || 0,
      });

      // Reset form state
      setSelectedPDF(null);
      setPageCount(null);

      // Start OCR processing in the background
      // await (workflowOrchMutation as unknown as ProcessPDFFn)({ pdfId }).catch(
      //   (error) => console.error("Error processing OCR:", error)
      // );

      // Set redirection URL to trigger navigation
      setRedirectUrl(`/pdf/${pdfId}/pages`);
      setIsLoading(false);
    } catch (error) {
      console.error("Error uploading PDF:", error);
      setIsLoading(false);
    }
  }

  // Handle chat card click to navigate to chat page
  const handleChatCardClick = async () => {
    // If there's a selected PDF, upload it first and then navigate to chat
    router.push("/chat");
  };

  return (
    <div
      className="flex flex-col md:flex-row justify-center items-center gap-6 min-h-screen md:h-full overflow-auto py-20 md:py-0 relative"
      style={{
        backgroundImage: 'url("/background.png")',
        backgroundSize: "cover",
        backgroundPosition: "center",
        backgroundRepeat: "no-repeat",
      }}
    >
      <section className="w-[300px] bg-white/10 backdrop-blur-md shadow-lg rounded-2xl p-6 border border-white/20 h-100 text-white hover:bg-white/20 transition-colors cursor-pointer">
        <h2 className="text-3xl font-semibold mb-4 text-right">
          ارفع مستنداتك
        </h2>
        <form className="space-y-4" onSubmit={(e) => e.preventDefault()}>
          <PDFDropzone
            selectedPDF={selectedPDF}
            setSelectedPDF={setSelectedPDF}
            pageCount={pageCount}
            setPageCount={setPageCount}
            isLoading={isLoading}
            setIsLoading={setIsLoading}
          />

          <UploadButton
            selectedPDF={selectedPDF}
            isLoading={isLoading}
            onSubmit={handleFormSubmit}
          />
        </form>
      </section>

      {/* Gold AI card */}
      <section
        className="w-[300px] shadow-lg rounded-2xl p-6 border border-amber-400 h-100 flex flex-col items-center justify-center"
        style={{
          background: "linear-gradient(145deg, #d4af37 10%, #b8860b 40%)",
          boxShadow: "0 10px 25px -5px rgba(180, 130, 20, 0.5)",
        }}
      >
        <TextGenerateEffectDemo />

        <p className="text-white font-medium text-center">
          تحويل المستندات إلى نصوص عن طريق الذكاء الإصطناعي
        </p>
      </section>

      {/* Chat card with onClick handler */}
      <section
        className="w-[300px] bg-white/10 backdrop-blur-md shadow-lg rounded-2xl p-6 border border-white/20 h-100 text-white hover:bg-white/20 transition-colors cursor-pointer"
        onClick={handleChatCardClick}
      >
        <h2 className="text-3xl font-semibold mb-4 text-right">
          تحدث مع مستنداتك
        </h2>
        <p className="text-white/80 text-right">تحدث مع مستنداتك بأسهل طريقة</p>

        {/* Chat icon from Lucide */}
        <div className="flex justify-center my-15">
          <MessageCircleMore className="w-20 h-20 text-white/80" />
        </div>
      </section>

      {/* QR Code Popup Component */}
      {showQRPopup && <QRCodePopup onClose={() => setShowQRPopup(false)} />}
    </div>
  );
}



// File Path: src/app/pdf/hooks/usePageQuery.tsx

import { useQuery } from "convex/react";
import { api } from "../../../../convex/_generated/api";
import type { PdfPageInfo } from "../types";
import type { Id } from "../../../../convex/_generated/dataModel";

export function usePagesQuery(pdfId: Id<"pdfs"> | undefined) {
  return useQuery(
    api.pdf.queries.getPagesByPdf,
    pdfId ? { pdfId } : "skip"
  ) as PdfPageInfo[] | undefined;
}


// File Path: src/app/pdf/pages/context.tsx

// src/app/pdf/pages/context.tsx (update)
"use client";

import React, { createContext, useContext, useState, ReactNode } from "react";

interface PdfPageContextValue {
  page: number;
  setPage: (page: number) => void;
  totalPages: number;
}

const PdfPageContext = createContext<PdfPageContextValue | undefined>(
  undefined
);

interface PdfPageProviderProps {
  children: ReactNode;
  initialPage?: number;
  totalPages?: number;
}

export const PdfPageProvider = ({
  children,
  initialPage = 1,
  totalPages = 0,
}: PdfPageProviderProps) => {
  const [page, setPage] = useState<number>(initialPage);

  const value = {
    page,
    setPage,
    totalPages,
  };

  return (
    <PdfPageContext.Provider value={value}>{children}</PdfPageContext.Provider>
  );
};

export const usePdfPage = () => {
  const context = useContext(PdfPageContext);
  if (context === undefined) {
    throw new Error("usePdfPage must be used within a PdfPageProvider");
  }
  return context;
};



// File Path: src/app/pdf/pages/StreamCleanPage.ts

// src/app/pdf/pages/streamCleanPage.ts (update with debounce)
import { Id } from "../../../../convex/_generated/dataModel";
import debounce from 'lodash.debounce';

export async function streamCleanPage(
  pageId: Id<"pages">, 
  src: "gemini" | "replicate", 
  onChunk: (c: string) => void,
  onError?: (error: Error) => void
): Promise<void> {
  console.log(`Starting stream cleaning for ${src} OCR of page ${pageId}`);
  
  try {
    const resp = await fetch(`${process.env.NEXT_PUBLIC_CONVEX_URL_HTTP}/cleanPage`, {
      method: "POST",
      headers: { 
        "Content-Type": "application/json",
        "Origin": window.location.origin
      },
      body: JSON.stringify({ pageId, source: src }),
    });

    if (!resp.ok) {
      const errorText = await resp.text();
      console.error(`Error from cleanPage endpoint (${resp.status}):`, errorText);
      throw new Error(`Server error: ${resp.status} - ${errorText}`);
    }

    if (!resp.body) {
      throw new Error('Response body is null');
    }

    const reader = resp.body.getReader();
    const decoder = new TextDecoder("utf-8");
    let fullText = "";
    
    // Create debounced update function
    const debouncedUpdate = debounce(onChunk, 300);
    
    // Start with an empty update to indicate streaming has begun
    onChunk("");
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const newChunk = decoder.decode(value, { stream: true });
      fullText += newChunk;
      
      // Use debounced update for smoother UI
      debouncedUpdate(fullText);
    }
    
    // Ensure final text is processed with any remaining decoder content
    const finalChunk = decoder.decode();
    if (finalChunk) {
      fullText += finalChunk;
    }
    
    // Flush pending debounced calls and do final update
    debouncedUpdate.flush();
    onChunk(fullText);
    
    console.log(`Completed stream cleaning for ${src} OCR of page ${pageId}`);
  } catch (error) {
    console.error(`Stream clean error for ${src} OCR of page ${pageId}:`, error);
    if (onError && error instanceof Error) {
      onError(error);
    } else if (error instanceof Error) {
      throw error;
    } else {
      throw new Error(String(error));
    }
  }
}


// File Path: src/app/pdf/StreamedTextBox.tsx

// src/app/pdf/StreamedTextBox.tsx
"use client";

import { Id } from "../../../convex/_generated/dataModel";
import { usePageStream, selectChunk } from "@/store/pageStreams";
import TypingIndicator from "@/app/components/TypingIndicator";
import { useQuery } from "convex/react";
import { api } from "../../../convex/_generated/api";
import { motion } from "motion/react";
import { CheckCircle, AlertCircle, Loader2 } from "lucide-react";

interface StreamedTextBoxProps {
  pageId: Id<"pages">;
  src: "gemini" | "replicate";
}

export default function StreamedTextBox({ pageId, src }: StreamedTextBoxProps) {
  // Get streaming text from store
  const chunks = usePageStream((state) => selectChunk(pageId, src)(state));

  // Get cleaning status for this page
  const pageResults = useQuery(
    src === "gemini"
      ? api.ocr.gemini.queries.getPageOcrResults
      : api.ocr.replicate.queries.getPageOcrResults,
    { pageId }
  );

  const cleaningResults = useQuery(
    api.ocr.openai.queries.getPageCleanedResults,
    {
      pageId,
      source: src,
    }
  );

  const isCompleted = cleaningResults?.cleaningStatus === "completed";
  const hasText = chunks && chunks.length > 0;
  const ocrStatus = pageResults?.ocrResults?.ocrStatus;

  // Determine status icon and message
  let statusIcon;
  let statusMessage;

  if (isCompleted) {
    statusIcon = <CheckCircle className="w-4 h-4 text-emerald-400" />;
    statusMessage = "اكتملت المعالجة";
  } else if (ocrStatus === "failed") {
    statusIcon = <AlertCircle className="w-4 h-4 text-red-400" />;
    statusMessage = "فشلت المعالجة";
  } else if (ocrStatus === "completed" && !hasText) {
    statusIcon = <Loader2 className="w-4 h-4 text-blue-400 animate-spin" />;
    statusMessage = "جاري تنقيح النص...";
  } else if (ocrStatus === "processing") {
    statusIcon = <Loader2 className="w-4 h-4 text-emerald-400 animate-spin" />;
    statusMessage = "جاري معالجة النص...";
  } else {
    statusIcon = <div className="w-4 h-4 rounded-full bg-gray-400/30" />;
    statusMessage = "في انتظار المعالجة...";
  }

  return (
    <motion.div
      initial={{ opacity: 0, y: 5 }}
      animate={{ opacity: 1, y: 0 }}
      className="relative space-y-2"
    >
      {/* Status Header */}
      <div className="flex items-center gap-2 text-xs text-white/70">
        {statusIcon}
        <span>{statusMessage}</span>
      </div>

      {/* Text Content */}
      {!hasText && !isCompleted ? (
        <div className="min-h-[100px] flex items-center justify-center bg-white/5 backdrop-blur-sm rounded-lg border border-white/10 p-4">
          <TypingIndicator />
        </div>
      ) : (
        <motion.div
          initial={{ height: 0 }}
          animate={{ height: "auto" }}
          transition={{ duration: 0.3 }}
          className="overflow-hidden"
        >
          <pre className="min-h-[100px] max-h-[250px] overflow-y-auto text-white/90 bg-white/5 backdrop-blur-sm rounded-lg border border-white/10 p-4 text-right font-sans text-xl whitespace-pre-wrap leading-relaxed">
            {chunks || "في انتظار المعالجة..."}
          </pre>
        </motion.div>
      )}
    </motion.div>
  );
}



// File Path: src/app/pdf/types.ts

import { Id } from "../../../convex/_generated/dataModel";

// OCR status values used across the application
export type OcrStatus = "pending" | "processing" | "completed" | "failed";

// Type for page information used in the pages accordion
export type PdfPageInfo = {
  pageId: Id<"pages">;
  pageNumber: number;
  geminiStatus: OcrStatus;
  replicateStatus: OcrStatus;
  cleanedSnippet: string | null;
};


// File Path: src/app/pdf/[storageId]/components/ErrorAlert.tsx

// src/app/pdf/[storageId]/components/ErrorAlert.tsx
import React from 'react';

interface ErrorAlertProps {
  message: string;
}

export default function ErrorAlert({ message }: ErrorAlertProps) {
  return (
    <div className="fixed top-4 right-4 bg-red-600/90 backdrop-blur-md text-white px-4 py-2 rounded-lg shadow-lg z-50 max-w-md">
      <div className="flex items-center">
        <svg xmlns="http://www.w3.org/2000/svg" className="h-6 w-6 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
        </svg>
        <span>{message}</span>
      </div>
    </div>
  );
}


// File Path: src/app/pdf/[storageId]/components/GeminiOCRSection.tsx

import React from 'react'
import MDXEditorWrapper from './MDXEditorWrapper'
import { formatTimestamp } from '../utils/formatUtils'

interface GeminiOCRProps {
  geminiResults: {
    ocrResults?: {
      processedAt?: number;
      confidenceScore?: number;
      extractedText?: string;
    }
  } | null | undefined;
  editedGeminiText: string;
  handleGeminiTextChange: (text: string) => void;
}

const GeminiOCRSection = ({ 
  geminiResults, 
  editedGeminiText, 
  handleGeminiTextChange 
}: GeminiOCRProps) => {
  return (
    <div className="bg-blue-100 p-4 rounded-lg mb-2">
      {/* <h3 className="text-xl font-medium text-blue-800 mb-2">Gemini OCR</h3> */}
      {geminiResults?.ocrResults ? (
        <div>
          <div className="text-sm text-gray-600 mb-2">
            Processed: {formatTimestamp(geminiResults.ocrResults.processedAt)}
          </div>
          <MDXEditorWrapper 
            markdown={editedGeminiText} 
            onChange={handleGeminiTextChange} 
          />
        </div>
      ) : (
        <div className="text-black italic">يتم الآن معالجة النصوص</div>
      )}
    </div>
  )
}

export default GeminiOCRSection 


// File Path: src/app/pdf/[storageId]/components/GlassmorphicProgressStepper.tsx

// src/app/pdf/[storageId]/components/GlassmorphicProgressStepper.tsx
import React from 'react';
import { CheckCircle, Loader2 } from 'lucide-react';

export type OcrStep = 'uploaded' | 'processing' | 'streaming' | 'completed';

interface GlassmorphicProgressStepperProps {
  currentStep: OcrStep;
  modelType: 'gemini' | 'replicate';
}

export default function GlassmorphicProgressStepper({ 
  currentStep,
  modelType
}: GlassmorphicProgressStepperProps) {
  // Define the ordered steps for display - first is rightmost in RTL
  const orderedSteps: { key: OcrStep; label: string }[] = [
    { key: 'uploaded', label: 'تحميل الملف' },
    { key: 'processing', label: 'معالجة النص' },
    { key: 'streaming', label: 'تنقيح النص' },
    { key: 'completed', label: 'اكتمل' }
  ];

  // Map the current step value to its index in our ordered steps
  const currentStepIndex = orderedSteps.findIndex(step => step.key === currentStep);
  
  // Process each step to determine its status
  const processedSteps = orderedSteps.map((step, index) => {
    // A step is completed if:
    // 1. We have moved past this step (index < currentStepIndex)
    // 2. Or it's the last step (index === orderedSteps.length - 1) and current step is 'completed'
    const isLastStep = index === orderedSteps.length - 1;
    const isCompleted = 
      index < currentStepIndex || 
      (isLastStep && currentStep === 'completed');
    
    const status = isCompleted ? 'completed' : 'loading';
    
    // Assign the appropriate icon based on status
    const icon = 
      status === 'completed' ? <CheckCircle className="w-5 h-5 text-emerald-400" /> :
      <Loader2 className="w-5 h-5 text-white/40 animate-spin" />;
    
    return {
      ...step,
      status,
      icon
    };
  });

  return (
    <div className="mb-2 rounded-lg bg-emerald-950/60 backdrop-blur-md border border-emerald-800/30 shadow-lg p-2" dir="rtl">
      {/* Render modelType label */}
      <div className="px-2 text-xs font-medium text-white mb-1">{modelType}</div>
      <div className="flex items-center justify-between px-1">
        {processedSteps.map((step, index) => (
          <React.Fragment key={step.key}>
            {/* Step with icon and label */}
            <div className="flex flex-col items-center">
              <div className={`flex items-center justify-center rounded-full w-7 h-7 
                ${step.status === 'completed' ? 'bg-emerald-600/20' : 'bg-white/10'}`}
              >
                {step.icon}
              </div>
              <span className={`text-xs mt-1 text-center
                ${step.status === 'completed' ? 'text-emerald-400' : 'text-white/40'}`}
              >
                {step.label}
              </span>
            </div>
            
            {/* Connector line between steps */}
            {index < processedSteps.length - 1 && (
              <div className="h-[1px] flex-1 mx-2 bg-gradient-to-l from-emerald-500/30 to-emerald-400/20" />
            )}
          </React.Fragment>
        ))}
      </div>
    </div>
  );
}


// File Path: src/app/pdf/[storageId]/components/MDXEditorWrapper.tsx

import dynamic from 'next/dynamic'

// Dynamically import MDXEditor to avoid SSR issues
const MDXEditorComponent = dynamic(
  () => import('@mdxeditor/editor').then((mod) => {
    const { MDXEditor } = mod
    return function MDXEditorWrapper({ markdown, onChange }: { markdown: string, onChange: (markdown: string) => void }) {
      return (
        <MDXEditor 
          markdown={markdown}
          onChange={onChange}
          contentEditableClassName="prose max-w-full text-black bg-white/90 p-3 rounded-lg border border-emerald-800/20 min-h-[200px] max-h-[300px] overflow-y-auto shadow-inner"
        />
      )
    }
  }),
  { ssr: false }
)

interface MDXEditorWrapperProps {
  markdown: string;
  onChange: (markdown: string) => void;
}

// This wrapper component is needed to handle the dynamic import
const MDXEditorWrapper = ({ markdown, onChange }: MDXEditorWrapperProps) => {
  return <MDXEditorComponent markdown={markdown} onChange={onChange} />
}

export default MDXEditorWrapper 


// File Path: src/app/pdf/[storageId]/components/MinimalistProgressBar.tsx

// src/app/pdf/[storageId]/components/MinimalistProgressBar.tsx
import React from "react";
import { OcrStep } from "./OcrProgressStepper";

interface MinimalistProgressBarProps {
  currentStep: OcrStep;
  modelType: "gemini" | "replicate";
}

export default function MinimalistProgressBar({
  currentStep,
  modelType,
}: MinimalistProgressBarProps) {
  // Define steps and their order
  const stepOrder: OcrStep[] = [
    "uploaded",
    "processing",
    "streaming",
    "completed",
  ];

  // Calculate progress percentage based on current step
  const currentIndex = stepOrder.indexOf(currentStep);
  const totalSteps = stepOrder.length;
  const progressPercentage = ((currentIndex + 1) / totalSteps) * 100;

  // Define model-specific styles
  const colorClasses = {
    gemini: "bg-blue-500",
    replicate: "bg-purple-500",
  };

  return (
    <div className="absolute top-0 left-0 right-0 h-1.5 rounded-t-lg">
      <div className="w-full h-full bg-white/10"></div>
      <div
        className={`absolute top-0 left-0 h-full transition-all duration-700 ease-in-out ${colorClasses[modelType]}`}
        style={{ width: `${progressPercentage}%` }}
      ></div>
    </div>
  );
}



// File Path: src/app/pdf/[storageId]/components/OcrProgressStepper.tsx

// src/app/pdf/[storageId]/components/OcrProgressStepper.tsx
import React from 'react';
import { CheckCircle, Clock, Loader2 } from 'lucide-react';

export type OcrStep = 'uploaded' | 'processing' | 'streaming' | 'completed';

interface OcrStepInfo {
  label: string;
  icon: React.ReactNode;
  status: 'completed' | 'current' | 'pending';
}

interface OcrProgressStepperProps {
  currentStep: OcrStep;
  modelType: 'gemini' | 'replicate';
}

export default function OcrProgressStepper({ currentStep, modelType }: OcrProgressStepperProps) {
  // Define steps for the OCR process
  const steps: Record<OcrStep, string> = {
    uploaded: 'تم رفع الملف',
    processing: 'جاري معالجة النص',
    streaming: 'جاري تحسين النص',
    completed: 'اكتمل'
  };

  // Create the step information array with status
  const stepInfo = Object.entries(steps).map(([key, label]) => {
    let status: 'completed' | 'current' | 'pending';
    
    if (key === currentStep) {
      status = 'current';
    } else if (
      (key === 'uploaded' && ['processing', 'streaming', 'completed'].includes(currentStep)) ||
      (key === 'processing' && ['streaming', 'completed'].includes(currentStep)) ||
      (key === 'streaming' && currentStep === 'completed')
    ) {
      status = 'completed';
    } else {
      status = 'pending';
    }

    return {
      key,
      label,
      status,
      icon: status === 'completed' ? (
        <CheckCircle className="w-6 h-6 text-green-500" />
      ) : status === 'current' ? (
        <Loader2 className="w-6 h-6 text-white animate-spin" />
      ) : (
        <Clock className="w-6 h-6 text-white/40" />
      )
    };
  }) as OcrStepInfo[];

  // Colors for model type
  const colorClasses = {
    gemini: 'from-blue-600 to-blue-800', // Blue for Gemini
    replicate: 'from-purple-600 to-purple-800' // Purple for Replicate
  };

  return (
    <div className="mb-4">
      <div className={`rounded-lg border border-white/20 p-3 bg-gradient-to-r ${colorClasses[modelType]} backdrop-blur-md shadow-lg`}>
        <h3 className="text-base font-medium mb-3 text-white text-right">
          {modelType === 'gemini' ? 'نموذج مغلق المصدر (جيميني)' : 'نموذج مفتوح المصدر (ريبليكت)'}
        </h3>
        
        <div className="flex items-center justify-between">
          {stepInfo.map((step, index) => (
            <React.Fragment key={step.key}>
              {/* Step circle with icon */}
              <div className="flex flex-col items-center">
                <div className={`rounded-full w-10 h-10 flex items-center justify-center border-2 ${
                  step.status === 'completed' ? 'border-green-500 bg-green-500/20' : 
                  step.status === 'current' ? 'border-white bg-white/20' : 
                  'border-white/40 bg-white/10'
                }`}>
                  {step.icon}
                </div>
                <span className={`text-xs mt-1 whitespace-nowrap ${
                  step.status === 'completed' ? 'text-green-300' : 
                  step.status === 'current' ? 'text-white' : 
                  'text-white/40'
                }`}>
                  {step.label}
                </span>
              </div>
              
              {/* Connector line between steps */}
              {index < stepInfo.length - 1 && (
                <div className={`h-0.5 flex-1 mx-1 ${
                  stepInfo[index + 1].status === 'completed' || 
                  stepInfo[index].status === 'completed' && stepInfo[index + 1].status === 'current' ? 
                  'bg-green-500' : 'bg-white/30'
                }`} />
              )}
            </React.Fragment>
          ))}
        </div>
      </div>
    </div>
  );
}


// File Path: src/app/pdf/[storageId]/components/OpenAICleanedSection.tsx




// File Path: src/app/pdf/[storageId]/components/pdfPreviewSection.tsx

import React from 'react'

export default function PdfPreviewSection({pdfUrl}: {pdfUrl: string | null}) {
  return (
    <div className="w-full h-full">
    {pdfUrl ? (
        <div className="bg-white/10 backdrop-blur-md shadow-lg rounded-2xl p-2 border border-white/20">
            <iframe
                src={pdfUrl}
                title="PDF Viewer"
                width="100%"
                height="500px"
                className="max-h-[900px] h-[50vh] md:h-[900px]"
                style={{ border: 'none', borderRadius: '12px' }}
            />
        </div>
    ) : (
        <div className="w-full h-[50vh] md:h-[900px] max-h-[900px] flex items-center justify-center bg-white/10 backdrop-blur-md rounded-2xl border border-white/20 text-white">
            Loading PDF...
        </div>
    )}
</div>
    
  )
}




// File Path: src/app/pdf/[storageId]/components/ReplicateOCRSection.tsx

